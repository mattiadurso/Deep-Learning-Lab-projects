{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2rmza982aG0"
   },
   "source": [
    "# Generative Adversarial Network (GANs)\n",
    "\n",
    "Generative Adversarial neural Networks (GANs) are a type of neural networks introduces Ian Goodfellow in his 2014 article [\"Generative Adversarial Nets\"](https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf). In GANs two neural networks contest with each other in a zero-sum game, where one network gain is the other network's loss.\n",
    "\n",
    "Given a training set, the objective of the GAN is to learn how to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics.\n",
    "\n",
    "This objective is achieved by using two networks, which are called **Generator** and **Discriminator**. The Generator is the network of the GAN which is tasked with generating new data similar to the training data starting from random noise, this with the objective to fool the discriminator with such new data. The task of a Discriminator is to classify an example and judge (discriminate) whether that data is authentic or if it was produced by the generator.\n",
    "\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=14_jILkGp9tIBeFTwTnRvZOCSWh90kaeX)\n",
    "\n",
    "\n",
    "The core idea of GANs is based on the \"indirect\" training of the generator through the discriminator, which itself is also being updated dynamically; this enables the models to learn how to classify and to produce new data in an *unsupervised* manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MR6VIL6XaDsJ"
   },
   "source": [
    "# Nuova sezione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A542wnDj5Sz2"
   },
   "source": [
    "In this exercise we will write a GAN with the task of generating and discriminating images from the MNIST dataset, a large database of handwritten digits commonly used for training various image processing systems.\n",
    "\n",
    "Let's start by importing all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JtKFSbu4dHZF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "from torch.utils import data as t_data\n",
    "import torchvision.datasets as datasets  # Since we handle image data we'll need some functionalities of torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KscDiTcodJeE"
   },
   "source": [
    "After the necessary imports, let's now load the dataset and write a DataLoader for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C_1NDMlrdLUb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/distiller/project/conda/conda-bld/pytorch_1591914925853/work/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([transforms.ToTensor()])  # Used to compose several transforms together\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=data_transforms)  # Importing the MNIST dataset\n",
    "\n",
    "batch_size=4\n",
    "\n",
    "# Dataloader for our dataset\n",
    "dataloader_mnist_train = t_data.DataLoader(mnist_trainset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cljH3WkvdRSR"
   },
   "source": [
    "Let's now write two helper functions:\n",
    "\n",
    "1.   *plot_img*, which will be used to plot 28x28 pixels images (belonging to the dataset or generated by the GAN);\n",
    "2.   *make_some_noise*, which will generate the random noise needed for the generator to work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QaO0FAgSdRez"
   },
   "outputs": [],
   "source": [
    "# Plots 28x28 pixels images\n",
    "def plot_img(array,number=None):\n",
    "    array = array.detach()\n",
    "    array = array.reshape(28,28)\n",
    "    \n",
    "    plt.imshow(array,cmap='binary')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if number:\n",
    "        plt.xlabel(number,fontsize='x-large')\n",
    "    plt.show()\n",
    "\n",
    "# Generates random noise\n",
    "def make_some_noise():\n",
    "    return torch.rand(batch_size,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bo6WC-F4dSHY"
   },
   "source": [
    "Let's write a *generator* class and create an instance of the generator with **input size 100** and **output size 784** (28*28). For the generator we'll use a sequential model with the following architecture:\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1L7BhtEBJ17tfjtPaM3LXsKHSLCJjoXH_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zl8tgsLrdVWf"
   },
   "outputs": [],
   "source": [
    "# Defining generator class\n",
    "class generator(nn.Module):\n",
    "    \n",
    "    # Generator architecture\n",
    "    def __init__(self, input_size, output_size):\n",
    "        \n",
    "        super(generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(input_size,300),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Linear(300,1000),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Linear(1000,800),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Linear(800,output_size)\n",
    "                                 )\n",
    "    \n",
    "    # Forward function\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiating the generator\n",
    "gen = generator(100,784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iz5aVqudWJa"
   },
   "source": [
    "Let's now write a *discriminator* class and create an instance of the discriminator with **input size 784** (which is the size of the images of both the dataset and the discriminator) and **output size 1**. Remember that the discriminator is a binary classifier, so it outputs only values between 0 and 1: values towards 0 denote an image classified as *fake*, while values towards 1 denote an image classified as *real*. For the discriminator we'll use a sequential model with the following architecture:\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1cdxrsoK_m40sqk4DGtMJox5F6F_RITrB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "luatiyNldWVM"
   },
   "outputs": [],
   "source": [
    "# Defining discriminator class\n",
    "class discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        \n",
    "        super(discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                                 nn.Linear(input_size,300),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Linear(300,300),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Linear(300,200),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Linear(200,output_size),\n",
    "                                 nn.Sigmoid()\n",
    "                                 )\n",
    "\n",
    "    # Forward function\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiating the discriminator\n",
    "dis = discriminator(784,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKzRasFydcyN"
   },
   "source": [
    "Since the discriminator has only to judge whether the image is real or not (by giving in output either 0 or 1) we can use BCE (Binary Cross-Entropy) as loss function of the GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SkCbTShUdc8b"
   },
   "outputs": [],
   "source": [
    "d_steps = 100  # Training steps done by the discriminator in each epoch \n",
    "g_steps = 100  # Training steps done by the generator in each epoch \n",
    "\n",
    "# Setting up two criterions for the discriminator: one will be used on real data, one on the generated data\n",
    "criteriond1 = nn.BCELoss()\n",
    "optimizerd1 = optim.SGD(dis.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "criteriond2 = nn.BCELoss()\n",
    "optimizerd2 = optim.SGD(gen.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "printing_steps = 200\n",
    "\n",
    "epochs = 50  # Training epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EelW7Ba3dfmV"
   },
   "source": [
    "Let's now set up the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fIKBATaPdfvv",
    "outputId": "8d32124c-bccb-430c-db89-6301c6137533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    \n",
    "    if epoch%10==0:\n",
    "        print(epoch)\n",
    "\n",
    "    # Training the discriminator\n",
    "    for d_step in range(d_steps):\n",
    "        dis.zero_grad()  # Zeroing the gradient\n",
    "        \n",
    "        # Training the discriminator on real data\n",
    "        for inp_real,_ in dataloader_mnist_train:\n",
    "            inp_real_x = inp_real\n",
    "            break\n",
    "\n",
    "        inp_real_x = inp_real_x.reshape(4,784)\n",
    "        dis_real_out = dis(inp_real_x)\n",
    "        dis_real_loss = criteriond1(dis_real_out,Variable(torch.ones(batch_size,1)))\n",
    "        dis_real_loss.backward()\n",
    "\n",
    "        # Training discriminator on the data produced by the generator\n",
    "        inp_fake_x_gen = make_some_noise()\n",
    "        dis_inp_fake_x = gen(inp_fake_x_gen).detach() # Getting a generator output\n",
    "        dis_fake_out = dis(dis_inp_fake_x)\n",
    "        dis_fake_loss = criteriond1(dis_fake_out,Variable(torch.zeros(batch_size,1)))\n",
    "        dis_fake_loss.backward()\n",
    "\n",
    "        optimizerd1.step()  # Optimization step\n",
    "        \n",
    "            \n",
    "    # Training the generator\n",
    "    for g_step in range(g_steps):\n",
    "        gen.zero_grad()  # Zeroing the gradient\n",
    "        \n",
    "        # Generating input data for the generator\n",
    "        gen_inp = make_some_noise() # CODE HERE\n",
    "        \n",
    "        # The output of the generator (the generated image) is fed to the discriminator\n",
    "        gen_out = gen(gen_inp)# CODE HERE\n",
    "        dis_out_gen_training = dis(gen_out)# CODE HERE\n",
    "\n",
    "        # Criterion applied on the judgement given by the discriminator on the generated image\n",
    "        gen_loss = criteriond2(dis_out_gen_training,Variable(torch.ones(batch_size,1)))\n",
    "        gen_loss.backward()\n",
    "        \n",
    "        optimizerd2.step()  # Optimization step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GddOhiS5dhs8"
   },
   "source": [
    "Now that we trained the GAN, let's generate both a fake image by giving some random noise to the generator and the label the discriminator has given to such image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "67njuZQ5dk02",
    "outputId": "7a5da303-05ba-43a5-98fa-12f3f03c72e7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9767], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "noise1 = make_some_noise()\n",
    "t1 = gen(noise1)\n",
    "plot_img(t1[0])\n",
    "print(dis(t1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "10_gans.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
