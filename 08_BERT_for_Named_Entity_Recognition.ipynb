{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjmT-x7w4nRp"
   },
   "source": [
    "# Named Entity Recognition with BERT\n",
    "\n",
    "In this assignment, we will tackled named **entity recognition using BERT**.\n",
    "\n",
    "We will use the MIT Movie dataset,\n",
    "which contains user-generated queries about films.\n",
    "Each sentence is annotated for the presence of various movie-specific entities such as ACTOR, PLOT, RATING, ...\n",
    "The tagging is performed using the **IOB** (Inside, Outsize, Begin) tagging scheme.\n",
    "\n",
    "Here are two sample sentences from the dataset (labels and words are separated by tabs, sentences are separated by empty lines).\n",
    "\n",
    "```\n",
    "O\tlist\n",
    "O\tthe\n",
    "B-RATINGS_AVERAGE\tfive\n",
    "I-RATINGS_AVERAGE\tstar\n",
    "O\trated\n",
    "O\tmovies\n",
    "O\tstarring\n",
    "B-ACTOR\tmel\n",
    "I-ACTOR\tgibson\n",
    "\n",
    "O\twhat\n",
    "B-GENRE\tscience\n",
    "I-GENRE\tfiction\n",
    "O\tfilms\n",
    "O\thave\n",
    "O\tcome\n",
    "O\tout\n",
    "B-YEAR\trecently\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0x6ISGEYKhL"
   },
   "source": [
    "# [1] Task and Dataset preprocessing\n",
    "\n",
    "As usual, let's start by downloading and preprocessing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8FXtXLe8aMfw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n",
      "unzip:  cannot find or open mit_movie.zip, mit_movie.zip.zip or mit_movie.zip.ZIP.\n",
      "total 2160\n",
      "-rw-------   1 mattiadurso  staff  216258 Oct 22 17:47 01_python-tutorial.ipynb\n",
      "-rw-------   1 mattiadurso  staff   36193 Jan 18 15:48 02_Data_Analysis_with_Pandas.ipynb\n",
      "-rw-------@  1 mattiadurso  staff   56092 Jan 18 16:00 03_Data_Preprocessing.ipynb\n",
      "-rw-r--r--@  1 mattiadurso  staff  101158 Nov 11 10:35 04 - Intro to pytorch.ipynb\n",
      "drwxr-xr-x@ 10 mattiadurso  staff     320 Jan 18 17:25 \u001b[34m05 - Embeddings and Sentiment with Neural Networks\u001b[m\u001b[m\n",
      "drwxr-xr-x@  6 mattiadurso  staff     192 Dec  2 10:27 \u001b[34m06_Image_Classification_with_CNNs\u001b[m\u001b[m\n",
      "drwxr-xr-x@  5 mattiadurso  staff     160 Jan 19 14:52 \u001b[34m07_object_detection\u001b[m\u001b[m\n",
      "-rw-------@  1 mattiadurso  staff  231662 Jan 24 14:32 08_BERT_for_Named_Entity_Recognition.ipynb\n",
      "-rw-------@  1 mattiadurso  staff   18614 Jan 24 14:15 09_Time_series_forecasting_with_LSTMs.ipynb\n",
      "-rw-------@  1 mattiadurso  staff   20533 Jan 24 14:15 10_gans.ipynb\n",
      "-rw-r--r--@  1 mattiadurso  staff       0 Oct 21 11:55 Icon?\n",
      "drwxr-xr-x@  5 mattiadurso  staff     160 Jan 24 12:02 \u001b[34mdata\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists(\"mit_movie.zip\"):\n",
    "    ! wget -O mit_movie.zip http://ailab.uniud.it/wp-content/uploads/2020/09/mit_movie.zip\n",
    "    ! unzip mit_movie.zip -d .\n",
    "    ! ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F86DouhpBRUC"
   },
   "source": [
    "## [1.1] Loading Dataset\n",
    "\n",
    "Let's first load the datasets and create lists of sentences and their respective labels:\n",
    "`train_sents`, `train_labels`, `test_sents` and `test_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MsWh0oKPYKhW"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_sents_and_labels_from_tsv(tsv_path):\n",
    "\n",
    "    with open(tsv_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "\n",
    "    output_sents = []\n",
    "    output_labels = []\n",
    "\n",
    "    current_tokens = []\n",
    "    current_labels = []\n",
    "\n",
    "    for line in tqdm(lines):\n",
    "        if line == \"\":\n",
    "            output_sents.append(current_tokens)\n",
    "            output_labels.append(current_labels)\n",
    "            current_tokens = []\n",
    "            current_labels = []\n",
    "        else:\n",
    "            label, text = line.split(\"\\t\")\n",
    "            current_tokens.append(text) # FILL WITH CODE\n",
    "            current_labels.append(label) # FILL WITH CODE\n",
    "\n",
    "    return output_sents, output_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160,
     "referenced_widgets": [
      "9ca403737eea44cba0951560c45d45c0",
      "d58ba19c5409425c92d9edf3a0980d81",
      "69634f6c89074d8e9cd32fa64e01149d",
      "cb662cb085884a409d380923008e3012",
      "07d091a38c4f4741b472cd77d45c4198",
      "0c94f75feff84f8b81ff614ce08f97e3",
      "66054312436647c090493d0c6b60b425",
      "ac5c3a86e2c542d0bba7bed655f1d986"
     ]
    },
    "id": "8FLayBUO_QYr",
    "outputId": "c0fe6124-3ef0-43aa-d0f4-2aba2849d82f"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'engtrain.bio.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8379e016609b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sents_and_labels_from_tsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"engtrain.bio.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of train samples\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First train sentence and its labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-86446f8dc8f8>\u001b[0m in \u001b[0;36mget_sents_and_labels_from_tsv\u001b[0;34m(tsv_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_sents_and_labels_from_tsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'engtrain.bio.txt'"
     ]
    }
   ],
   "source": [
    "train_sents, train_labels = get_sents_and_labels_from_tsv(\"engtrain.bio.txt\")\n",
    "\n",
    "print(\"Number of train samples\", len(train_sents))\n",
    "print()\n",
    "print(\"First train sentence and its labels\")\n",
    "print(train_sents[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160,
     "referenced_widgets": [
      "52a8200b035e49d2813c9ac717171939",
      "91e8ed335c0c4cea88b386ed0b8b8d00",
      "1600a79df0f843a9af7497643626d973",
      "a2666cc375524e94aead509bf0947190",
      "cf8558d970554f1ab6576b5580b9a7a6",
      "6a68a454e0d34bd883c88243cc8c9bf7",
      "e2415066725f4a90a26c234d60616fe6",
      "54dd581b25fe4eb2b0170663b1ab8d29"
     ]
    },
    "id": "V4K1EVtBYKhb",
    "outputId": "3fc15a39-bbb5-4e4d-ffdf-75037b4d6dfb"
   },
   "outputs": [],
   "source": [
    "test_sents, test_labels = get_sents_and_labels_from_tsv(\"engtest.bio.txt\")\n",
    "\n",
    "print(\"Number of test samples\", len(train_sents))\n",
    "print()\n",
    "print(\"First test sentence and its labels\")\n",
    "print(test_sents[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UF9nQCJFBsSq"
   },
   "source": [
    "## [1.2] Looking at the entities\n",
    "Let's now take a closer look at the kind of entities present in the datasets: we are going to count the frequency of each entity in the train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "p3eq0lVSYKhh",
    "outputId": "79b2a258-1f9a-4aaa-d7a6-9b1ece35c333"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_test_labels = []\n",
    "\n",
    "for sent in test_labels:\n",
    "    for label in sent:\n",
    "        label = label if label == \"O\" else label[2:]\n",
    "        all_test_labels.append(label)\n",
    "        \n",
    "all_train_labels = []\n",
    "\n",
    "for sent in train_labels:\n",
    "    for label in sent:\n",
    "        label = label if label == \"O\" else label[2:]\n",
    "        all_train_labels.append(label)\n",
    "\n",
    "most_common_test = Counter(all_test_labels).most_common()\n",
    "most_common_train = Counter(all_train_labels).most_common()\n",
    "\n",
    "matrix = []\n",
    "for i,j in zip(most_common_train, most_common_test):\n",
    "    matrix.append([i[0],i[1], j[0], j[1]])\n",
    "\n",
    "import pandas as pd\n",
    "most_common_df = pd.DataFrame(matrix,\n",
    "                              columns=[\"train_labels\", \"train_labels_freq\",\n",
    "                                       \"test_labels\", \"test_labels_freq\"])\n",
    "display(most_common_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAS5IiFKCJ2N"
   },
   "source": [
    "There are a lot of entities in this dataset!\n",
    "\n",
    "We might want to **remove some of the least frequent labels, or focus on one kind of entity in particular**.\n",
    "\n",
    "In this case we are not going to remove anything, so the next cell will have no effect. But you can try and add labels to the `labels_to_remove` list and see how that influences the performance of the final classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWoUcYpWYKhq"
   },
   "outputs": [],
   "source": [
    "labels_to_remove = [] #[\"SONG\", \"REVIEW\", \"TRAILER\", \"CHARACTER\"]\n",
    "for del_label in labels_to_remove:\n",
    "    \n",
    "    for i, sent in enumerate(train_labels):\n",
    "        for j, label in enumerate(sent):\n",
    "            if label == del_label or label[2:] == del_label:\n",
    "                train_labels[i][j] = \"O\"\n",
    "    \n",
    "    for i, sent in enumerate(test_labels):\n",
    "        for j, label in enumerate(sent):\n",
    "            if label == del_label or label[2:] == del_label:\n",
    "                test_labels[i][j] = \"O\"\n",
    "keep_IB = True\n",
    "if not keep_IB:\n",
    "    for i, sent in enumerate(train_labels):\n",
    "        for j, label in enumerate(sent):\n",
    "            if \"-\" in label:\n",
    "                train_labels[i][j] = label[2:]\n",
    "    \n",
    "    for i, sent in enumerate(test_labels):\n",
    "        for j, label in enumerate(sent):\n",
    "            if \"-\" in label:\n",
    "                test_labels[i][j] = label[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7puVBoGqKtg"
   },
   "source": [
    "# [2] Pytorch BERT\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers), released in late 2018, deep pre-trained architecture for language modelling.\n",
    "\n",
    "You can either use these models to extract high quality language features from your text data, or you can **fine-tune** them on a **specific task** (classification, entity recognition, question answering, etc.) with your own data to produce state of the art predictions.\n",
    "\n",
    "When a model is **pre-trained**, it is provided with **all of its layers already trained for a specific task** (in this case language modelling) on some large corpus (in this case a dump of Wikipedia and other resources).\n",
    "\n",
    "We can simply **add an untrained layer of neurons on the end of the model**, and train the new model for our named entity recognition task, leveraging on the knowledge given by the pre-training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zZz5dbXBYvP"
   },
   "source": [
    "$$\n",
    "\\begin{array}{ccccccc|c}\n",
    "\\\\\n",
    "\\boxed{\\small{\\text{O}}} & \\boxed{\\small{\\text{O}}} & \\boxed{\\small{\\text{O}}} & \\boxed{\\small{\\text{O}}} & \\boxed{\\small{\\text{B-ACT}}} & \\boxed{\\small{\\text{I-ACT}}} & \\boxed{\\small{\\text{O}}}\n",
    "& \\small{\\text{output NER labels}}\\\\\n",
    "\\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow \\\\ \\hline\n",
    "&&&\\textbf{Classifier}&&& & \\small{\\text{untrained layer}}\\\\ \\hline\n",
    "\\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow \\\\\n",
    "\\boxed{H_{\\small{\\text{[CLS]}}}} & \\boxed{H_\\text{what}} & \\boxed{H_\\text{movies}} & \\boxed{H_\\text{star}} & \\boxed{H_\\text{bruce}} & \\boxed{H_\\text{willis}} & \\boxed{H_{\\small{\\text{[SEP]}}}} & \\small{\\text{output embeddings}}\\\\\n",
    "\\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow \\\\ \\hline\n",
    "&&&\\textbf{Layer 12}&&& & \\small{\\text{BERT pretrained layer}} \\\\ \\hline\n",
    "\\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "\\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow \\\\ \\hline\n",
    "&&&\\textbf{Layer 2}&&& & \\small{\\text{BERT pretrained layer}} \\\\ \\hline\n",
    "\\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow \\\\ \\hline\n",
    "&&&\\textbf{Layer 1}&&& & \\small{\\text{BERT pretrained layer}} \\\\ \\hline\n",
    "\\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow & \\uparrow \\\\\n",
    "\\boxed{\\small{\\text{[CLS]}}} & \\boxed{\\text{what}} & \\boxed{\\text{movies}} & \\boxed{\\text{star}} & \\boxed{\\text{bruce}} & \\boxed{\\text{willis}} & \\boxed{\\small{\\text{[SEP]}}} & \\small{\\text{input}} \\\\\n",
    "\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wAA2elCqRja"
   },
   "source": [
    "Let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT.\n",
    "\n",
    "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. It also includes pre-built modifications of these models suited for specific task. For example, in this lab we will use `BertForTokenClassification`.\n",
    "(but there are also other classes for sequence classification, question answering, next sentence prediciton, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgHln5M9qUV8",
    "outputId": "6ea5b707-1a6f-47af-d64a-2f03d354fa71"
   },
   "outputs": [],
   "source": [
    "!pip install 'transformers==3.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwaMbZjx4C_A"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIHzBzxWWCrp"
   },
   "source": [
    "# [3] Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SNKvP-iqW86"
   },
   "source": [
    "## [3.1] About BERT tokenization\n",
    "\n",
    "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
    "\n",
    "The tokenization must be performed by the tokenizer **included with BERT**, which performs a special kind of tokenization called **Wordpiece tokenization**. This allows to map virtually any word to a token without using any special \"out of vocabulary\" or \"unknown\" tokens.\n",
    "\n",
    "The cell below will download the tokenizer for us. We'll be using the \"uncased\" version of BERT (`bert-base-uncased`) in this example, meaning that the model was pre-trained on text that was only lower-case.\n",
    "\n",
    "When creating the `tokenizer` we need specify both the kind of BERT model we want to use and the fact that we want the tokenizer to convert every string to lower case (`do_lower_case=True`), otherwise the `tokenizer` will produce tokens that the model will not understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8xPeWi2mqfu0",
    "outputId": "6fabdc01-a463-4087-cb2d-1940ca4e736b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjPW_MDDqnPs"
   },
   "source": [
    "Let's apply the tokenizer to one sentence just to see the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SiiSPfp7qmo2",
    "outputId": "15bdb7d0-69c0-4e09-df27-8f49468e29f4"
   },
   "outputs": [],
   "source": [
    "# Print the original sentence.\n",
    "sent = \"I like eating strawberries with my friend Mike.\"\n",
    "print('Original: ', sent)\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sent))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUQPYZrvqi6X"
   },
   "source": [
    "\n",
    "As we can see, the tokenizer converts every word to lower case. It also **splits some words into smaller pieces**, called wordpieces: the word `strawberries` becomes the two tokens `straw` and `#berries`. This helps the BERT model to understand new words by breaking them into smaller pieces and analyzing them separately.\n",
    "\n",
    "The last line shows the numericalization of the tokens: each number is the index of that token in the vocabulary of the model, similarly to what happened in the first bag-of-word approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGowL7FZqx9-"
   },
   "source": [
    "Apart from tokenizing the words and numericalizing them, we also need to use some **special tokens** which were included in the pretraining of BERT.\n",
    "\n",
    "- **`[SEP]`**: signals to BERT the end of the sentence. It is especially useful in tasks where you need to give two sentences as an input (e.g. entailment).\n",
    "\n",
    "- **`[CLS]`**: in classification tasks we must prepend the special `[CLS]` token to the beginning of every sentence.\n",
    "BERT consists of 12 Transformer layers. Each transformer takes in a list of token embeddings, and produces the same number of embeddings on the output (but with the feature values changed).\n",
    "If we were performing sentence classification then in the output of the final (12th) transformer, *only the first embedding (corresponding to the [CLS] token) would be used by the classifier*.\n",
    "But we will be performing **token classification**, so we will use the output of all of the tokens.\n",
    "\n",
    "- **`[PAD]`**: padding token, used to make all sequences have the same length. Padding tokens will also be ignore when calculating the loss of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKoM9C1RleYU"
   },
   "source": [
    "## [3.2] Tokenizing the dataset\n",
    "\n",
    "Now that we know more about how BERT tokenizers work, let's tokenize our input texts.\n",
    "\n",
    "The `transformers` library offers a lot of automated functions to tokenize texts, add special tokens and pad. But unfortunately we can not make use of them.\n",
    "\n",
    "We are dealing with a very special case: we have **one label for each word in the text**. And each word might get split into subtokens by the wordpiece tokenizer of BERT. This is something we need to keep track of by hand: **we need tokenize the text and and the labels at the same time** to make sure that the lists have the same length!\n",
    "\n",
    "Here is an example tagging FRUITS:\n",
    "\n",
    "|| | | | | | | |\n",
    "|--|--------------|-----|-------|--------|---|---|---|\n",
    "|**Original text and labels**| Strawberries | and | green | apples | . | | |\n",
    "|| B | O | B | I | O | | |\n",
    "\n",
    "|| | | | | | | |\n",
    "|--|--------------|-----|-------|--------|---|---|---|\n",
    "|**After BERT tokenization** | Straw|##berries | and | green | apple|##s | . |\n",
    "| | B | I | O | B | I | I | O |\n",
    "\n",
    "As you can see, \"Strawberries\" was split into two sub-words, so we had to split its label `B` into two labels: `B` and `I`. Sames goes for \"apples\": its original label `I` was split into two new labels `I` and `I`.\n",
    "\n",
    "The function `tokenize_and_preserve_labels` will take care of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yspuT04ldp0"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(tokens, labels, bert_tokenizer):\n",
    "    '''\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \n",
    "    See also:\n",
    "    https://gab41.lab41.org/lessons-learned-fine-tuning-bert-for-named-entity-recognition-4022a53c0d90\n",
    "    '''\n",
    "\n",
    "    extended_tokens = []\n",
    "    extended_labels = []\n",
    "\n",
    "    for (word, label) in zip(tokens, labels):\n",
    "        \n",
    "        # Tokenize the word and count number of subwords the word is broken into\n",
    "        tokenized_word = bert_tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word) # FILL WITH CODE\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        extended_tokens.extend(tokenized_word) # FILL WITH CODE\n",
    "\n",
    "        # Add the label to the new list of labels `n_subwords` times\n",
    "        suffix = ''\n",
    "        if len(label) > 1:\n",
    "            suffix = label[1:]  # suffix is the \"ACTOR\" in \"B-ACTOR\"\n",
    "\n",
    "        # if the original label is B -> B I I ...\n",
    "        if label[0] == 'B':\n",
    "            extended_labels.extend([f'B{suffix}']+[f'I{suffix}'] * (n_subwords-1)) # FILL WITH CODE\n",
    "        # if the original label is I -> I I I ...\n",
    "        # or the origianl label is O -> O O O ...\n",
    "        else:\n",
    "            extended_labels.extend([label]*n_subwords) # FILL WITH CODE\n",
    "        \n",
    "    assert(len(extended_labels) == len(extended_tokens))\n",
    "\n",
    "    CLS = bert_tokenizer.cls_token\n",
    "    PAD = bert_tokenizer.pad_token\n",
    "    SEP = bert_tokenizer.sep_token\n",
    "\n",
    "    # adding special tokens\n",
    "    extended_tokens = [CLS] + extended_tokens + [SEP]\n",
    "    extended_labels = [\"O\"] + extended_labels + [\"O\"]\n",
    "    \n",
    "    return extended_tokens, extended_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNQAwWaLTZe6"
   },
   "source": [
    "Great, let's see if this function works by tokenizing the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549,
     "referenced_widgets": [
      "15effca7a0064fe28c329756cea19097",
      "d98794536d854936932a0fb77e61e1ec",
      "4faee018cd924ac39d4a6ea42229e7a9",
      "8f9b5baf8884441aacdd1f8a0ee19d61",
      "b93280f4b90b4fd48a177f331fac7b0a",
      "e45216d405a44225bd2d213f3994c253",
      "e8f7834f2e5944a4a9dbeebfff17d646",
      "81dcf2d9bd08484b98ae88e797069ca4"
     ]
    },
    "id": "38Nt2iPvtV4k",
    "outputId": "abe9cb51-faca-40fd-c04b-ab1355ad3bd0"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "train_tokens = []\n",
    "train_toklabels = []\n",
    "\n",
    "for sentence, labels in zip(tqdm(train_sents), train_labels):\n",
    "    toks, toklabels = tokenize_and_preserve_labels(sentence, labels, tokenizer)\n",
    "    train_tokens.append(toks)\n",
    "    train_toklabels.append(toklabels)\n",
    "\n",
    "idx = 7\n",
    "print(\"-\"*30)\n",
    "for s,l in zip(train_sents[idx], train_labels[idx]):\n",
    "    print(f\"{s:<15}| {l}\")\n",
    "print(\"-\"*30)\n",
    "for s,l in zip(train_tokens[idx], train_toklabels[idx]):\n",
    "    print(f\"{s:<15}| {l}\")\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3Unfjy-wTrJ"
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "```text\n",
    "------------------------------\n",
    "do             | O\n",
    "you            | O\n",
    "have           | O\n",
    "any            | O\n",
    "thrillers      | B-GENRE\n",
    "directed       | O\n",
    "by             | O\n",
    "sofia          | B-DIRECTOR\n",
    "coppola        | I-DIRECTOR\n",
    "------------------------------\n",
    "[CLS]          | O\n",
    "do             | O\n",
    "you            | O\n",
    "have           | O\n",
    "any            | O\n",
    "thriller       | B-GENRE\n",
    "##s            | I-GENRE\n",
    "directed       | O\n",
    "by             | O\n",
    "sofia          | B-DIRECTOR\n",
    "cop            | I-DIRECTOR\n",
    "##pol          | I-DIRECTOR\n",
    "##a            | I-DIRECTOR\n",
    "[SEP]          | O\n",
    "------------------------------\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567,
     "referenced_widgets": [
      "c850a43175af4a3c9bbb25f0dc7e9dfa",
      "5778942ac05f4572bd5f1009a5139da3",
      "5effb93a82c64ae7a1d302f18c03cd91",
      "6bdbaa9908fd4ed08d4945ede3eac858",
      "f344d4f9b7ec404dbaf97517b9343e0e",
      "84a7429948114fb8a6c9a60034cbdc8e",
      "6e6bacfe97de461f89a2daafa6ce3f34",
      "8272a55e6dad45e491164311fee60252"
     ]
    },
    "id": "oRkrYrNLuo5b",
    "outputId": "e736d856-2a19-434a-df45-2d733c4949af"
   },
   "outputs": [],
   "source": [
    "test_tokens = []\n",
    "test_toklabels = []\n",
    "\n",
    "# FILL WITH CODE\n",
    "for sentence, labels in zip(tqdm(test_sents),test_labels):\n",
    "  toks, toklabels = tokenize_and_preserve_labels(sentence, labels, tokenizer)\n",
    "  test_tokens.append(toks)\n",
    "  test_toklabels.append(toklabels)\n",
    "\n",
    "\n",
    "\n",
    "idx = 7\n",
    "print(\"-\"*30)\n",
    "for s,l in zip(test_sents[idx], test_labels[idx]):\n",
    "    print(f\"{s:<15}| {l}\")\n",
    "print(\"-\"*30)\n",
    "for s,l in zip(test_tokens[idx], test_toklabels[idx]):\n",
    "    print(f\"{s:<15}| {l}\")\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_c7pjUogGyBp"
   },
   "source": [
    "## [3.3] Padding all texts and labels\n",
    "\n",
    "We need all input sequences to be of the same length.\n",
    "Since we have one output label for each token of the sequence, labels will need padding too!\n",
    "We will pad the sentences with the special `[PAD]` token of the BERT tokenizer. Different tokenizers might use different strings for the special token, so it's always safer to use `tokenizer.pad_token`.\n",
    "We decide to pad labels with the same padding token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1vkJnesYKiR"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 50\n",
    "\n",
    "def pad_sequence(sequence, max_len, pad_item):\n",
    "    \n",
    "    length_of_padding = max_len - len(sequence) # FILL WITH CODE\n",
    "    \n",
    "    # If the sequence is too short: pad it\n",
    "    if length_of_padding >= 0: \n",
    "        padding = [pad_item] * length_of_padding # FILL WITH CODE\n",
    "        out = sequence + padding\n",
    "    \n",
    "    # If the sequence is too long: cut it\n",
    "    elif length_of_padding < 0: \n",
    "        out = sequence[:max_len] # FILL WITH CODE\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mMQTvBBxI9X",
    "outputId": "1afdb5f0-c8a2-468c-cb24-468796ef78f1"
   },
   "outputs": [],
   "source": [
    "padded_train_tokens = [pad_sequence(t, MAX_SEQ_LEN, tokenizer.pad_token) for t in train_tokens]\n",
    "padded_train_labels = [pad_sequence(t, MAX_SEQ_LEN, tokenizer.pad_token) for t in train_toklabels]\n",
    "print(\" \".join(padded_train_tokens[0]))\n",
    "print(\" \".join(padded_train_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7UiSY8LUKDP"
   },
   "source": [
    "**Expected output:**\n",
    "```\n",
    "[CLS] what movies star bruce willis [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
    "O O O O B-ACTOR I-ACTOR O [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfy3n8SGx24L",
    "outputId": "49a484e5-e085-4a6c-9e2f-51d29a0aa829"
   },
   "outputs": [],
   "source": [
    "padded_test_tokens = [pad_sequence(t, MAX_SEQ_LEN, tokenizer.pad_token) for t in test_tokens]\n",
    "padded_test_labels = [pad_sequence(t, MAX_SEQ_LEN, tokenizer.pad_token) for t in test_toklabels]\n",
    "print(\" \".join(padded_test_tokens[0]))\n",
    "print(\" \".join(padded_test_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-Mqqz5pUahD"
   },
   "source": [
    "**Expected output:**\n",
    "```\n",
    "[CLS] are there any good romantic comedies out right now [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
    "O O O O O B-GENRE I-GENRE O B-YEAR I-YEAR O [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjVzC1Ee0lfH"
   },
   "source": [
    "## [3.4] Attention masks\n",
    "\n",
    "Despite their name, they have nearly nothing to do with the attention mechanism of BERT!\n",
    "They are an additional input for the BERT model and they are used to **distinguish padding tokens from real tokens**.\n",
    "\n",
    "Padding tokens will have a 0 in their mask, while real tokens (including [CLS] and [SEP]) will have a 1.\n",
    "\n",
    "Example\n",
    "```\n",
    "[CLS] are there any good romantic comedies out right now [SEP] [PAD] [PAD] [PAD] [PAD]\n",
    "1     1   1     1   1    1        1        1   1     1   1     0     0     0     0\n",
    "```\n",
    "\n",
    "Attention masks are importat: **the loss of the model will be calculated on all the token which have a 1 in their mask**. Models will not generate errors or warnings if attention masks are not given as an input, but they will create a default mask of ones (so padding tokens will be considered as real tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJ0reeQvFpnf",
    "outputId": "444c39a8-8f2b-4d87-983f-bb3501af04b1"
   },
   "outputs": [],
   "source": [
    "train_attention_mask = [[0 if t==tokenizer.pad_token else 1 for t in tokens] for tokens in padded_train_tokens]\n",
    "test_attention_mask = [[0 if t==tokenizer.pad_token else 1 for t in tokens] for tokens in padded_test_tokens] # FILL WITH CODE\n",
    "\n",
    "for t,m in zip(padded_train_tokens[7],train_attention_mask[7]):\n",
    "    print(f\"{m}  {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IKT31naWN5X"
   },
   "source": [
    "# [4] Numericalization and Dataloaders\n",
    "\n",
    "Now we are ready to turn all the strings (tokens and labels) into numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9UEXm0aWhXf"
   },
   "source": [
    "## [4.1] Numericalize the tokens\n",
    "\n",
    "We can easily confer all the tokens to numbers using the `tokenizer`: `tokenizer.convert_tokens_to_ids()` takes as input a list of tokens and returns a list of int, representing the index of the tokens in the tokenizer's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugMS3zfryiEo",
    "outputId": "ef4b72e0-60c2-4224-fe64-6fde24ee2c67"
   },
   "outputs": [],
   "source": [
    "padded_train_ids = [tokenizer.convert_tokens_to_ids(t) for t in padded_train_tokens] # FILL WITH CODE\n",
    "padded_test_ids = [tokenizer.convert_tokens_to_ids(t) for t in padded_test_tokens] # FILL WITH CODE\n",
    "\n",
    "print(padded_train_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6QRVCsXEaS1"
   },
   "source": [
    "## [4.2] Numericalize the labels\n",
    "\n",
    "This time we are going to need to numericalize the labels too. Frist of all we will create `label_map` (a \"vocabulary\" for labels) which will map each label to an int. This map will include a value for the padding label too. We will set the padding label to -1 to make it clearly different from the numericalization of the other real labels.\n",
    "\n",
    "Let's write a function `create_label_map` to generate a dictionary and map each label to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2ca4CcMYKhl"
   },
   "outputs": [],
   "source": [
    "def create_label_map(dataset_labels):\n",
    "    \n",
    "    all_labels = set()\n",
    "    \n",
    "    for sent in dataset_labels:\n",
    "        for label in sent:\n",
    "            all_labels.add(label)\n",
    "\n",
    "    label_map = {label:val for val, label in enumerate(all_labels)} # FILL WITH CODE\n",
    "    label_map[tokenizer.pad_token] = -1 # FILL WITH CODE\n",
    "        \n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "vPBn4kamCD8z",
    "outputId": "a2220142-a28e-4895-88c6-35b4c624353e"
   },
   "outputs": [],
   "source": [
    "label_map = create_label_map(train_labels)\n",
    "print(len(label_map), \"labels\")\n",
    "display(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idarW8Y9XaJZ"
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "26 labels\n",
    "{'B-ACTOR': 4,\n",
    " 'B-CHARACTER': 5,\n",
    " 'B-DIRECTOR': 21,\n",
    " 'B-GENRE': 1,\n",
    " 'B-PLOT': 18,\n",
    " 'B-RATING': 19,\n",
    " 'B-RATINGS_AVERAGE': 3,\n",
    " 'B-REVIEW': 10,\n",
    " 'B-SONG': 8,\n",
    " 'B-TITLE': 14,\n",
    " 'B-TRAILER': 20,\n",
    " 'B-YEAR': 2,\n",
    " 'I-ACTOR': 7,\n",
    " 'I-CHARACTER': 0,\n",
    " 'I-DIRECTOR': 17,\n",
    " 'I-GENRE': 16,\n",
    " 'I-PLOT': 6,\n",
    " 'I-RATING': 9,\n",
    " 'I-RATINGS_AVERAGE': 15,\n",
    " 'I-REVIEW': 24,\n",
    " 'I-SONG': 22,\n",
    " 'I-TITLE': 12,\n",
    " 'I-TRAILER': 13,\n",
    " 'I-YEAR': 23,\n",
    " 'O': 11,\n",
    " '[PAD]': -1}```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3E_7M_n9FZe3"
   },
   "source": [
    "We can now use this function to conver all the padded labels into their numericalized version!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-9ANAJ2YKh8",
    "outputId": "1270a6ce-991d-472e-8066-1e3c282e4cae"
   },
   "outputs": [],
   "source": [
    "padded_train_labels_int = [[label_map[l] for l in labels] for labels in padded_train_labels] # FILL WITH CODE\n",
    "padded_test_labels_int = [[label_map[l] for l in labels] for labels in padded_test_labels] # FILL WITH CODE\n",
    "\n",
    "print(\"Actual text and labels\\n\", train_sents[7], \"\\n\", train_labels[7])\n",
    "print(\"\\nTokenized text and labels\\n\", padded_train_tokens[7], \"\\n\", padded_train_labels[7])\n",
    "print(\"\\nText_ids and numericalized labels:\\n\", padded_train_ids[7], \"\\n\", padded_train_labels_int[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKIOFxc0XzSE"
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "\n",
    "```\n",
    "Actual text and labels\n",
    " ['do', 'you', 'have', 'any', 'thrillers', 'directed', 'by', 'sofia', 'coppola'] \n",
    " ['O', 'O', 'O', 'O', 'B-GENRE', 'O', 'O', 'B-DIRECTOR', 'I-DIRECTOR']\n",
    "\n",
    "Tokenized text and labels\n",
    " ['[CLS]', 'do', 'you', 'have', 'any', 'thriller', '##s', 'directed', 'by', 'sofia', 'cop', '##pol', '##a', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] \n",
    " ['O', 'O', 'O', 'O', 'O', 'B-GENRE', 'I-GENRE', 'O', 'O', 'B-DIRECTOR', 'I-DIRECTOR', 'I-DIRECTOR', 'I-DIRECTOR', 'O', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
    "\n",
    "Text_ids and numericalized labels:\n",
    " [101, 2079, 2017, 2031, 2151, 10874, 2015, 2856, 2011, 8755, 8872, 18155, 2050, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
    " [11, 11, 11, 11, 11, 1, 16, 11, 11, 21, 17, 17, 17, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ryyf0l60G6N7"
   },
   "source": [
    "## [4.3] Tensor Datasets and Data Loaders\n",
    "\n",
    "We can now create our two Tensor Datasets!\n",
    "\n",
    "We will also add a new field to our Dataset: an **unique id for each sample**. This will be useful later to map all the predictions of the model back to the corresponding sample.\n",
    "So the fields of our datasets will be:\n",
    "1. input ids\n",
    "2. labels (numericalized, one for each token)\n",
    "3. attention mask\n",
    "4. unique id for the text sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coIzi40EYKir"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "input_ids_train = torch.LongTensor(padded_train_ids)\n",
    "attention_masks_train = torch.LongTensor(train_attention_mask)\n",
    "labels_train = torch.LongTensor(padded_train_labels_int)\n",
    "sample_ids_train = torch.LongTensor(range(len(input_ids_train)))\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train, sample_ids_train)\n",
    "\n",
    "input_ids_test = torch.LongTensor(padded_test_ids) # FILL WITH CODE\n",
    "attention_masks_test = torch.LongTensor(test_attention_mask) # FILL WITH CODE\n",
    "labels_test = torch.LongTensor(padded_test_labels_int) # FILL WITH CODE\n",
    "sample_ids_test = torch.LongTensor(range(len(input_ids_test))) # FILL WITH CODE\n",
    "\n",
    "test_dataset = TensorDataset(input_ids_test, attention_masks_test, labels_test, sample_ids_test) # FILL WITH CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMtpWMrBYKi1",
    "outputId": "0ca5c1a4-5f7d-474c-85fc-3a4fd5a1adb8"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our train and test sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# Craete the test_dataloader on the test_dataset\n",
    "# Use a SequentialSampler instead of a RandomSampler to pull out batches sequentially\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset, # FILL WITH CODE\n",
    "            sampler = SequentialSampler(test_dataset), # FILL WITH CODE\n",
    "             batch_size = batch_size # FILL WITH CODE\n",
    "        )\n",
    "\n",
    "print(\"Number of train batches:\", len(train_dataloader))\n",
    "print(\"Number of test batches: \", len(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfKPN0ylYKi5"
   },
   "source": [
    "# [5] The actual model!\n",
    "\n",
    "We can now finally instantiate our BERT model for token classification.\n",
    "\n",
    "We will use a `BertConfig` to configure some options of the model: what kind of BERT we want to use (version base uncased) and the number of output labels for out NER task. Note that we count the labels using the length of the `label_map` minus one (we don't need the model to predict the padding label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ucnv9r_dYKi6",
    "outputId": "31d595ca-f7c0-4fe4-fd53-7e915f37e966"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification, AdamW, BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\", num_labels = len(label_map)-1)\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    config = config\n",
    ")\n",
    "\n",
    "device_id = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.to(device_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRIbyJ41N6qI"
   },
   "source": [
    "With that in mind, let's define the functions to train and test the model: they are pretty similar to the ones you are already used to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTlwds89YKjD"
   },
   "outputs": [],
   "source": [
    "def train_bert_one_epoch(model, dataloader, epoch):\n",
    "    \n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    # Put the model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        # `batch` contains four pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        #   [3]: sample ids\n",
    "        b_input_ids = batch[0].to(device_id)\n",
    "        b_input_mask = batch[1].to(device_id)\n",
    "        b_labels = batch[2].to(device_id)\n",
    "        \n",
    "        # Always clear any previously calculated gradients before performing a backward pass\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        loss, logits = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask, \n",
    "                            labels=b_labels)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_loss = total_loss / len(dataloader)            \n",
    "    \n",
    "    print(\"  Average loss: {0:.4f}\".format(avg_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oKbpNNDN_te"
   },
   "source": [
    "During testing we will actually **save the predictions in a dataframe** (a table) to compute some metrics at a later time.\n",
    "\n",
    "`result_df` is a dataframe with **a line for each test sample** and three columns: one for the `text_ids`, one for the real labels (`gold_labels`) and one for the predictions of the model (`gold_labels`).\n",
    "\n",
    "It starts as completely empty, and the test function will populate it thanks to the sample ids that we have included in our dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "eMP6xj9dYKi_",
    "outputId": "cbe70909-dfce-4feb-e11d-cad3804a572b"
   },
   "outputs": [],
   "source": [
    "result_df_index = [int(d[-1]) for d in test_dataset]\n",
    "result_df_columns = [\"text_ids\", \"gold_labels\", \"pred_labels\"]\n",
    "result_df = pd.DataFrame(index=result_df_index, columns=result_df_columns)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4oLypRWYKjH"
   },
   "outputs": [],
   "source": [
    "def test_bert(model, dataloader):\n",
    "\n",
    "    print(\"Testing\")\n",
    "    \n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    # Put the model into testing mode\n",
    "    model.eval() # FILL WITH CODE\n",
    "\n",
    "    # For each batch of testing data...\n",
    "    for step, batch in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        # Unpack this test batch from our dataloader. \n",
    "        # `batch` contains four pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        #   [3]: sample ids\n",
    "        b_input_ids = batch[0].to(device_id) # FILL WITH CODE\n",
    "        b_input_mask = batch[1].to(device_id) # FILL WITH CODE\n",
    "        b_labels = batch[2].to(device_id) # FILL WITH CODE\n",
    "        sample_ids = batch[3].to(device_id) # FILL WITH CODE\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Perform a forward pass (evaluate the model on this test batch).\n",
    "            (loss, logits) = model(b_input_ids,\n",
    "                                   token_type_ids=None,\n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels) # FILL WITH CODE\n",
    "\n",
    "        # Accumulate the test loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        \n",
    "        # No need to backpropagate on the loss.\n",
    "        # Let's calculate the accuracy instead.\n",
    "        \n",
    "        # Move logits and labels to CPU\n",
    "        #logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        preds = torch.argmax(logits, axis=-1)\n",
    "        \n",
    "        for idx_, text_, target_, pred_ in zip(sample_ids, b_input_ids, b_labels, preds):\n",
    "            idx_ = int(idx_)\n",
    "            result_df.at[idx_, \"text_ids\"] = text_.tolist()\n",
    "            result_df.at[idx_, \"gold_labels\"] = target_.tolist()\n",
    "            result_df.at[idx_, \"pred_labels\"] = pred_.tolist()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        #total_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_loss = total_loss / len(dataloader)            \n",
    "    \n",
    "    print(\"  Average loss: {0:.4f}\".format(avg_loss))\n",
    "\n",
    "    \n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_accuracy = total_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uj87Ow2ZOW96"
   },
   "source": [
    "Let's create the optimizer and scheduler for the model (this is the defaul setup for BERT in this library) and train the model for 4 epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9DLpP283ava"
   },
   "outputs": [],
   "source": [
    "BERT_EPOCHS = 4\n",
    "\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "optimizer = AdamW(model.parameters(),\n",
    "                    lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                    eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * BERT_EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nclAwzCmZmZO"
   },
   "source": [
    "Training will take approximately 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312,
     "referenced_widgets": [
      "4e42e7c2ecc54a8788f636e0eee2247a",
      "527f01a335d14fdd9fdebb433fbb25a9",
      "b0ae8eb765c742b2916f57801942bf28",
      "1ff1f4dbe42642bf98419ae8bdb590bb",
      "267e97cec84f4dc4a57e9b6201419fdd",
      "d6c0f24125bb430abe5efddb7a50f3ba",
      "74e8fa17d0fd44848e152fbed98edfdf",
      "246c23848a08498aadd2b7d09106c06b",
      "32f9870007e7460994194c57a3ae1f8a",
      "a6ab012e369a4e168d25ada582c3131e",
      "6bc6961ed40a47cbb4d08e095f207753",
      "17a6e8c00b314a4d8233fe38a8b27b3c",
      "a2930803d90244609e11300202f2d0ef",
      "39ed24386afb4a019cdc5bbd5db41d0b",
      "717383740b5e420cac433660ba2fa9d4",
      "487335e576ee4580bfba688c8782cdaf",
      "c5ff65923bd24dc683155f4c4e62d00c",
      "69f1f50015694c27bdc8f69a6afbf18c",
      "747dae5216c142d1aeb521acd56687d5",
      "16a0c00f907344818cbfca5a46b9cfcc",
      "9f911dc880634330ab4e9d592414fad2",
      "cfebee450d94456cbb6c8a8d74b0fe25",
      "fcea304bc3ed4b76bf4ccf873fe1c2df",
      "28626cb069bc4db1b144adc4c4b591ff",
      "f60c8169d9ed4f0db216ff11c44da039",
      "d6bb97b85b1b4e5cae1370f2fabb1dab",
      "b7b880a552d14227891919f8b2f574d4",
      "6a2131ef099a4a79ae5ebce7aa183dbe",
      "b748943a4b0a435eb520002db7ecec3a",
      "b456ebae518f42af9ea85190158b70a6",
      "ecd610bf62f843158f05bd7df996a8cd",
      "11cbc54ce62b48cea9c5ca1e7bb7a56f"
     ]
    },
    "id": "pb23h9MxYKjK",
    "outputId": "c27677a0-76e9-4d64-8aaf-d051828afbac"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "print(\"training\")\n",
    "for epoch in range(BERT_EPOCHS):\n",
    "    train_bert_one_epoch(model, train_dataloader, epoch) # FILL WITH CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pQ7m71aOc5-"
   },
   "source": [
    "Testing the model will populate `result_df` with the predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685,
     "referenced_widgets": [
      "2cf86f786d4f4407b1de01ab9aeb1fd3",
      "89f5be99fb0c45619d69b6748bcaa7b9",
      "95ad2b371c01407faa1409d9cdf32679",
      "4b46a136495545338f1f3870d4532142",
      "fac6f2d995884111b61d6c5c748555f5",
      "6bca42db9aa84529912e5319a0b3c2f3",
      "16194c314fed47608b2ecfb8a9726bcb",
      "c7d0d0e149dc46efbe728dd5fd56d9b8"
     ]
    },
    "id": "hqNOqsvv6KWi",
    "outputId": "c9207909-88f5-4431-a072-c513e53e847f"
   },
   "outputs": [],
   "source": [
    "test_bert(model, test_dataloader) # FILL WITH CODE\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxNVgRwBOmJO"
   },
   "source": [
    "# [6] Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AJC1K_gZ2w0"
   },
   "source": [
    "In this last part we will finally take a look at some NER metrics to understand the performance of the model.\n",
    "\n",
    "Before starting we will create two new columns in our `result_df`: `gold_no_pad` and `pred_no_pad`. In this way the padding tokens will not create problems in our evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945
    },
    "id": "QiT_ZFGDYKjR",
    "outputId": "81b42125-ac22-4d3c-ce5d-99f78815ef01"
   },
   "outputs": [],
   "source": [
    "result_df[\"gold_no_pad\"] = None\n",
    "result_df[\"pred_no_pad\"] = None\n",
    "\n",
    "for idx, row in result_df.iterrows():\n",
    "\n",
    "    gold = row.gold_labels\n",
    "    pred = row.pred_labels\n",
    "\n",
    "    first_pad = gold.index(-1)\n",
    "    \n",
    "    result_df.loc[idx, \"gold_no_pad\"] = gold[:first_pad]\n",
    "    result_df.loc[idx, \"pred_no_pad\"] = pred[:first_pad]\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_UG9TBXPRGg"
   },
   "source": [
    "In the setting of named entity recognitions metrics can be computed either at **token level** or at **entity level**.\n",
    "\n",
    "Token-level metrics are usually way more \"optimistic\" than entity level ones, as they do not check if the whole entity is being detected, but just look at the general distribution of the output labels.\n",
    "\n",
    "On the other side, entity-level metrics are more difficult to compute and there is no widespread agreement on how to compute them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgHNTSJ0O5x9"
   },
   "source": [
    "## [6.1] Token level metrics\n",
    "\n",
    "Here we will calculate precision, recall and f1 score for all the samples, aggregated by entity type.\n",
    "\n",
    "Note that we are not considering the padding when calculating these metrics: we are dropping all the items for which the gold label is -1 (our chosen padding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sByGu1EYYKjZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def calc_metrics_TOKEN(gold_list, pred_list):\n",
    "        \n",
    "    all_gold = np.array(gold_list).flat\n",
    "    all_pred = np.array(pred_list).flat\n",
    "    \n",
    "    gold_flat = []\n",
    "    pred_flat = []\n",
    "    \n",
    "    for gold, pred in zip(all_gold, all_pred):\n",
    "        if gold != -1:\n",
    "            gold_flat.append(gold)\n",
    "            pred_flat.append(pred)\n",
    "            \n",
    "    gold_flat = np.array(gold_flat)\n",
    "    pred_flat = np.array(pred_flat)\n",
    "    \n",
    "    return precision_recall_fscore_support(gold_flat, pred_flat, labels=list(range(len(label_map))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 928
    },
    "id": "NSxWJ5G4lLY4",
    "outputId": "891e95cf-90b9-4746-d952-c2273c2c3f9b"
   },
   "outputs": [],
   "source": [
    "pre, rec, f1, supp = calc_metrics_TOKEN(result_df.gold_labels.tolist(), result_df.pred_labels.tolist())\n",
    "\n",
    "label_map_ = {v:k for k,v in label_map.items()}\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"label_id\": list(range(len(label_map))),\n",
    "    \"precision\": pre,\n",
    "    \"recall\": rec,\n",
    "    \"f1\": f1,\n",
    "    \"support\": supp,\n",
    "})\n",
    "metrics_df.index = [label_map_[x] for x in label_map_.keys()]\n",
    "metrics_df.drop(\"[PAD]\", axis=0, inplace=True)\n",
    "metrics_df.sort_values(by=\"support\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2OdoICIPCGc"
   },
   "source": [
    "## [6.2] Entity level metrics\n",
    "\n",
    "We are going to calculate the entity level metrics using the metrics defined by the International Workshop on Semantic Evaluation (SemEval).\n",
    "\n",
    "A brief history of different metrics for NER can be found at here: http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/\n",
    "\n",
    "The author of the post also provides an implementation to evaluate all the mentioned metrics.\n",
    "We are going to use a sligtly modified (improved?) version of its code, located in the file `ner_eval.py` (it was downloaded together with the dataset and you can find it in the file section of colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "bRJBAgJHihUT",
    "outputId": "46da0e1d-8571-4cf4-c95a-8f03c854b079"
   },
   "outputs": [],
   "source": [
    "from ner_eval import *\n",
    "\n",
    "def calc_metrics_ENTITY(gold_list, pred_list):\n",
    "        \n",
    "    all_gold = []\n",
    "    all_pred = []\n",
    "\n",
    "    for g in gold_list:\n",
    "        all_gold.append([label_map_[x] for x in g])\n",
    "    for p in pred_list:\n",
    "        all_pred.append([label_map_[x] for x in p])\n",
    "\n",
    "    all_entities = list(label_map.keys())\n",
    "    all_entities = [e[2:] for e in all_entities if e not in [\"O\",\"[PAD]\"]]\n",
    "    \n",
    "    evaluator = Evaluator(all_gold, all_pred, all_entities)\n",
    "            \n",
    "    results, results_agg = evaluator.evaluate()\n",
    "\n",
    "    return results_agg\n",
    "\n",
    "res = calc_metrics_ENTITY(result_df.gold_no_pad.tolist(), result_df.pred_no_pad.tolist())\n",
    "\n",
    "\"\"\"\n",
    "            | check boundaries  |\n",
    "            | correct           |\n",
    "            +--------+----------+\n",
    "            | Y      | N        |\n",
    "--------+---+--------+----------+\n",
    "check   | Y | strict | ent_type |\n",
    "entity  +---+--------+----------+\n",
    "correct | N | exact  | partial  |\n",
    "--------+---+--------+----------+\n",
    "\n",
    "\"\"\"\n",
    "new_res = {}\n",
    "for k in res.keys():\n",
    "    new_res[k] = res[k][\"partial\"]\n",
    "df = pd.DataFrame.from_dict(new_res, orient=\"index\")\n",
    "df[\"f1\"] = (2*df[\"precision\"]*df[\"recall\"]) / (df[\"precision\"]+df[\"recall\"])\n",
    "df.columns = df.columns.str.replace(\"^(.+)\", \"partial \\g<1>\")\n",
    "\n",
    "new_res = {}\n",
    "for k in res.keys():\n",
    "    new_res[k] = res[k][\"strict\"]\n",
    "df2 = pd.DataFrame.from_dict(new_res, orient=\"index\")\n",
    "df2[\"f1\"] = (2*df2[\"precision\"]*df2[\"recall\"]) / (df2[\"precision\"]+df2[\"recall\"])\n",
    "df2.columns = df2.columns.str.replace(\"^(.+)\", \"strict \\g<1>\")\n",
    "\n",
    "df = pd.concat([df, df2], axis=1)\n",
    "display(df[[\"strict precision\", \"strict recall\", \"strict f1\",\n",
    "            \"partial precision\", \"partial recall\", \"partial f1\"]]\\\n",
    "        .sort_values(by=\"partial f1\", ascending=False))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "08 BERT for Named Entity Recognition.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07d091a38c4f4741b472cd77d45c4198": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0c94f75feff84f8b81ff614ce08f97e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11cbc54ce62b48cea9c5ca1e7bb7a56f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15effca7a0064fe28c329756cea19097": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4faee018cd924ac39d4a6ea42229e7a9",
       "IPY_MODEL_8f9b5baf8884441aacdd1f8a0ee19d61"
      ],
      "layout": "IPY_MODEL_d98794536d854936932a0fb77e61e1ec"
     }
    },
    "1600a79df0f843a9af7497643626d973": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a68a454e0d34bd883c88243cc8c9bf7",
      "max": 27129,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf8558d970554f1ab6576b5580b9a7a6",
      "value": 27129
     }
    },
    "16194c314fed47608b2ecfb8a9726bcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16a0c00f907344818cbfca5a46b9cfcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28626cb069bc4db1b144adc4c4b591ff",
      "placeholder": "​",
      "style": "IPY_MODEL_fcea304bc3ed4b76bf4ccf873fe1c2df",
      "value": " 306/306 [01:46&lt;00:00,  2.88it/s]"
     }
    },
    "17a6e8c00b314a4d8233fe38a8b27b3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_487335e576ee4580bfba688c8782cdaf",
      "placeholder": "​",
      "style": "IPY_MODEL_717383740b5e420cac433660ba2fa9d4",
      "value": " 306/306 [03:21&lt;00:00,  1.52it/s]"
     }
    },
    "1ff1f4dbe42642bf98419ae8bdb590bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_246c23848a08498aadd2b7d09106c06b",
      "placeholder": "​",
      "style": "IPY_MODEL_74e8fa17d0fd44848e152fbed98edfdf",
      "value": " 306/306 [01:34&lt;00:00,  3.24it/s]"
     }
    },
    "246c23848a08498aadd2b7d09106c06b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "267e97cec84f4dc4a57e9b6201419fdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "28626cb069bc4db1b144adc4c4b591ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cf86f786d4f4407b1de01ab9aeb1fd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_95ad2b371c01407faa1409d9cdf32679",
       "IPY_MODEL_4b46a136495545338f1f3870d4532142"
      ],
      "layout": "IPY_MODEL_89f5be99fb0c45619d69b6748bcaa7b9"
     }
    },
    "32f9870007e7460994194c57a3ae1f8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6bc6961ed40a47cbb4d08e095f207753",
       "IPY_MODEL_17a6e8c00b314a4d8233fe38a8b27b3c"
      ],
      "layout": "IPY_MODEL_a6ab012e369a4e168d25ada582c3131e"
     }
    },
    "39ed24386afb4a019cdc5bbd5db41d0b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "487335e576ee4580bfba688c8782cdaf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b46a136495545338f1f3870d4532142": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7d0d0e149dc46efbe728dd5fd56d9b8",
      "placeholder": "​",
      "style": "IPY_MODEL_16194c314fed47608b2ecfb8a9726bcb",
      "value": " 77/77 [00:07&lt;00:00,  9.93it/s]"
     }
    },
    "4e42e7c2ecc54a8788f636e0eee2247a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b0ae8eb765c742b2916f57801942bf28",
       "IPY_MODEL_1ff1f4dbe42642bf98419ae8bdb590bb"
      ],
      "layout": "IPY_MODEL_527f01a335d14fdd9fdebb433fbb25a9"
     }
    },
    "4faee018cd924ac39d4a6ea42229e7a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e45216d405a44225bd2d213f3994c253",
      "max": 9775,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b93280f4b90b4fd48a177f331fac7b0a",
      "value": 9775
     }
    },
    "527f01a335d14fdd9fdebb433fbb25a9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52a8200b035e49d2813c9ac717171939": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1600a79df0f843a9af7497643626d973",
       "IPY_MODEL_a2666cc375524e94aead509bf0947190"
      ],
      "layout": "IPY_MODEL_91e8ed335c0c4cea88b386ed0b8b8d00"
     }
    },
    "54dd581b25fe4eb2b0170663b1ab8d29": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5778942ac05f4572bd5f1009a5139da3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5effb93a82c64ae7a1d302f18c03cd91": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84a7429948114fb8a6c9a60034cbdc8e",
      "max": 2443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f344d4f9b7ec404dbaf97517b9343e0e",
      "value": 2443
     }
    },
    "66054312436647c090493d0c6b60b425": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69634f6c89074d8e9cd32fa64e01149d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c94f75feff84f8b81ff614ce08f97e3",
      "max": 109266,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07d091a38c4f4741b472cd77d45c4198",
      "value": 109266
     }
    },
    "69f1f50015694c27bdc8f69a6afbf18c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a2131ef099a4a79ae5ebce7aa183dbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11cbc54ce62b48cea9c5ca1e7bb7a56f",
      "placeholder": "​",
      "style": "IPY_MODEL_ecd610bf62f843158f05bd7df996a8cd",
      "value": " 306/306 [01:34&lt;00:00,  3.24it/s]"
     }
    },
    "6a68a454e0d34bd883c88243cc8c9bf7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bc6961ed40a47cbb4d08e095f207753": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39ed24386afb4a019cdc5bbd5db41d0b",
      "max": 306,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a2930803d90244609e11300202f2d0ef",
      "value": 306
     }
    },
    "6bca42db9aa84529912e5319a0b3c2f3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bdbaa9908fd4ed08d4945ede3eac858": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8272a55e6dad45e491164311fee60252",
      "placeholder": "​",
      "style": "IPY_MODEL_6e6bacfe97de461f89a2daafa6ce3f34",
      "value": " 2443/2443 [00:01&lt;00:00, 1562.84it/s]"
     }
    },
    "6e6bacfe97de461f89a2daafa6ce3f34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "717383740b5e420cac433660ba2fa9d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "747dae5216c142d1aeb521acd56687d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cfebee450d94456cbb6c8a8d74b0fe25",
      "max": 306,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f911dc880634330ab4e9d592414fad2",
      "value": 306
     }
    },
    "74e8fa17d0fd44848e152fbed98edfdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81dcf2d9bd08484b98ae88e797069ca4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8272a55e6dad45e491164311fee60252": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84a7429948114fb8a6c9a60034cbdc8e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89f5be99fb0c45619d69b6748bcaa7b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f9b5baf8884441aacdd1f8a0ee19d61": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81dcf2d9bd08484b98ae88e797069ca4",
      "placeholder": "​",
      "style": "IPY_MODEL_e8f7834f2e5944a4a9dbeebfff17d646",
      "value": " 9775/9775 [00:08&lt;00:00, 1141.88it/s]"
     }
    },
    "91e8ed335c0c4cea88b386ed0b8b8d00": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95ad2b371c01407faa1409d9cdf32679": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bca42db9aa84529912e5319a0b3c2f3",
      "max": 77,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fac6f2d995884111b61d6c5c748555f5",
      "value": 77
     }
    },
    "9ca403737eea44cba0951560c45d45c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_69634f6c89074d8e9cd32fa64e01149d",
       "IPY_MODEL_cb662cb085884a409d380923008e3012"
      ],
      "layout": "IPY_MODEL_d58ba19c5409425c92d9edf3a0980d81"
     }
    },
    "9f911dc880634330ab4e9d592414fad2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a2666cc375524e94aead509bf0947190": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54dd581b25fe4eb2b0170663b1ab8d29",
      "placeholder": "​",
      "style": "IPY_MODEL_e2415066725f4a90a26c234d60616fe6",
      "value": " 27129/27129 [00:03&lt;00:00, 8955.63it/s]"
     }
    },
    "a2930803d90244609e11300202f2d0ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a6ab012e369a4e168d25ada582c3131e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac5c3a86e2c542d0bba7bed655f1d986": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0ae8eb765c742b2916f57801942bf28": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6c0f24125bb430abe5efddb7a50f3ba",
      "max": 306,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_267e97cec84f4dc4a57e9b6201419fdd",
      "value": 306
     }
    },
    "b456ebae518f42af9ea85190158b70a6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b748943a4b0a435eb520002db7ecec3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b7b880a552d14227891919f8b2f574d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b456ebae518f42af9ea85190158b70a6",
      "max": 306,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b748943a4b0a435eb520002db7ecec3a",
      "value": 306
     }
    },
    "b93280f4b90b4fd48a177f331fac7b0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c5ff65923bd24dc683155f4c4e62d00c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_747dae5216c142d1aeb521acd56687d5",
       "IPY_MODEL_16a0c00f907344818cbfca5a46b9cfcc"
      ],
      "layout": "IPY_MODEL_69f1f50015694c27bdc8f69a6afbf18c"
     }
    },
    "c7d0d0e149dc46efbe728dd5fd56d9b8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c850a43175af4a3c9bbb25f0dc7e9dfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5effb93a82c64ae7a1d302f18c03cd91",
       "IPY_MODEL_6bdbaa9908fd4ed08d4945ede3eac858"
      ],
      "layout": "IPY_MODEL_5778942ac05f4572bd5f1009a5139da3"
     }
    },
    "cb662cb085884a409d380923008e3012": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac5c3a86e2c542d0bba7bed655f1d986",
      "placeholder": "​",
      "style": "IPY_MODEL_66054312436647c090493d0c6b60b425",
      "value": " 109266/109266 [00:03&lt;00:00, 33992.05it/s]"
     }
    },
    "cf8558d970554f1ab6576b5580b9a7a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cfebee450d94456cbb6c8a8d74b0fe25": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d58ba19c5409425c92d9edf3a0980d81": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6bb97b85b1b4e5cae1370f2fabb1dab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6c0f24125bb430abe5efddb7a50f3ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d98794536d854936932a0fb77e61e1ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2415066725f4a90a26c234d60616fe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e45216d405a44225bd2d213f3994c253": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8f7834f2e5944a4a9dbeebfff17d646": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecd610bf62f843158f05bd7df996a8cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f344d4f9b7ec404dbaf97517b9343e0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f60c8169d9ed4f0db216ff11c44da039": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b7b880a552d14227891919f8b2f574d4",
       "IPY_MODEL_6a2131ef099a4a79ae5ebce7aa183dbe"
      ],
      "layout": "IPY_MODEL_d6bb97b85b1b4e5cae1370f2fabb1dab"
     }
    },
    "fac6f2d995884111b61d6c5c748555f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fcea304bc3ed4b76bf4ccf873fe1c2df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
