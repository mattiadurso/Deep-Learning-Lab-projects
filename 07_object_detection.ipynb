{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZP0Mhlbbjwf"
   },
   "source": [
    "# Object Detection\n",
    "Object detection is a task in the computer vision field of study which aims to *identify and locate objects* in an image or video, annotating such video with *labels* which explain the class in which the identified objects have been placed by the neural network. \n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1562QV_NqoQOPDmhSYzDnUwlnqHiU7lTy)\n",
    "\n",
    "With this kind of identification and localization, object detection can be used not only to count the objects, animals and/or persons appearing in a scene but it is also possible to determine and to track their precise locations in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvTac4iidtdG"
   },
   "source": [
    "In this exercise we will use a *pretrained* neural network, the Inception Resnet V2 (Version 2) architecture proposed by Google and based on the usage of stacked layers of Convolutional Neural Networks and Pooling Layers. A detailed scheme of the architecture follows.\n",
    "\n",
    "![image](https://drive.google.com/uc?id=1gSxcfYxBbVLHcl4MhjiZqb78woS6SnLD)\n",
    "\n",
    "A pretrained neural network, as the name suggests, is a network which was already trained and so is ready to be applied on any new input given to it; this process is called *inference*.\n",
    "Before using the Inception Resnet V2 though, it's first necessary to import and write some supporting functions, hence let's start by importing all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BKtJULZLNrD3"
   },
   "outputs": [],
   "source": [
    "# Libraries needed to run the inference on the TF-Hub module\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Libraries needed to download the images\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "from six import BytesIO\n",
    "\n",
    "# Libraries needed to draw onto the image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n",
    "\n",
    "import time # Used to measure the inference time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNMbbL7yT39A"
   },
   "source": [
    "Now we need to write some functions to handle the images we will feed to the network and to draw the bounding boxes over such images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I6sDCxBOT4MM"
   },
   "outputs": [],
   "source": [
    "# Plots the image\n",
    "def display_image(image):\n",
    "  fig = plt.figure(figsize=(20, 15))\n",
    "  plt.grid(False)\n",
    "  plt.imshow(image)\n",
    "\n",
    "# Downloads and resizes the image\n",
    "def download_and_resize_image(url, new_width=256, new_height=256, display=False):\n",
    "\n",
    "  # Downloading the image\n",
    "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
    "  response = urlopen(url)\n",
    "  image_data = response.read()\n",
    "  image_data = BytesIO(image_data)\n",
    "  pil_image = Image.open(image_data)\n",
    "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
    "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
    "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
    "  #print(\"Image downloaded to %s.\" % filename)\n",
    "\n",
    "  # Resizing and actual plotting\n",
    "  if display:\n",
    "    display_image(pil_image)\n",
    "  return filename\n",
    "\n",
    "# Draws a bounding box over an image\n",
    "def draw_bounding_box_on_image(image, ymin, xmin, ymax, xmax, color, font,\n",
    "                               thickness=4, display_str_list=()):\n",
    "  \n",
    "  \n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  \n",
    "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                ymin * im_height, ymax * im_height)\n",
    "  \n",
    "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "             (left, top)],\n",
    "            width=thickness, fill=color)\n",
    "\n",
    "  # If the total height of the display strings added to the top of the bounding\n",
    "  # box exceeds the top of the image, stack the strings below the bounding box\n",
    "  # instead of above.\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = top + total_display_str_height\n",
    "\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    \n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    \n",
    "    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                    (left + text_width, text_bottom)],\n",
    "                   fill=color)\n",
    "    \n",
    "    draw.text((left + margin, text_bottom - text_height - margin),\n",
    "              display_str, fill=\"white\", font=font)\n",
    "    \n",
    "    text_bottom -= text_height - 2 * margin\n",
    "\n",
    "# Overlays labeled boxes on an image with formatted scores and label names\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
    "\n",
    "  colors = list(ImageColor.colormap.values())\n",
    "\n",
    "  try:\n",
    "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/arial.ttf\",\n",
    "                              25)\n",
    "  except IOError:\n",
    "    #print(\"Font not found, using default font.\")\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  for i in range(min(boxes.shape[0], max_boxes)):\n",
    "    if scores[i] >= min_score:\n",
    "      \n",
    "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "      \n",
    "      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
    "                                     int(100 * scores[i]))\n",
    "      \n",
    "      color = colors[hash(class_names[i]) % len(colors)]\n",
    "      \n",
    "      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "      \n",
    "      draw_bounding_box_on_image(image_pil,\n",
    "                                 ymin, xmin, ymax, xmax, color,\n",
    "                                 font,\n",
    "                                 display_str_list=[display_str])\n",
    "      \n",
    "      np.copyto(image, np.array(image_pil))\n",
    "  \n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hU2ZFsarUACj"
   },
   "source": [
    "Now, let's import an image we can give to the network. For this exercise we'll use the \"Naxos Taverna\" image, which we'll use as a sample image to see the performance of the object detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7xCe_OxkUAL-"
   },
   "outputs": [],
   "source": [
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg\"\n",
    "downloaded_image_path = download_and_resize_image(image_url, 1280, 856, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEY044kKVaG2"
   },
   "source": [
    "We can now import the pre-trained module from [here](https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1); we will use Inception Resnet V2 with its default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zG3vNHrGVdX5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
    "detector = hub.load(module_handle).signatures['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VY9sO7SxVgeW"
   },
   "source": [
    "Let's now write the function to run the pretrained network on our sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "C2A9aE1WVgFa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 objects.\n",
      "{'detection_class_entities': array([b'Chair', b'Umbrella', b'Kitchen & dining room table', b'Table',\n",
      "       b'Chair', b'Chair', b'Chair', b'Chair', b'Chair', b'Table',\n",
      "       b'Chair', b'Tree', b'Tree', b'Chair', b'Tree', b'Chair', b'Tree',\n",
      "       b'Tree', b'Tree', b'Tree', b'Tree', b'Tree', b'Chair', b'Chair',\n",
      "       b'Flower', b'Tree', b'Tree', b'Flower', b'Umbrella', b'Tree',\n",
      "       b'Tree', b'Tree', b'Tree', b'Porch', b'Table', b'Tree', b'Tree',\n",
      "       b'Tree', b'Table', b'Tree', b'Tree', b'Flower', b'Table', b'Tree',\n",
      "       b'Tree', b'Tree', b'Tree', b'Tree', b'Tree', b'Chair', b'Tree',\n",
      "       b'Flower', b'Table', b'Tree', b'Tree', b'Chair', b'Tree', b'Chair',\n",
      "       b'Tree', b'Tree', b'Tree', b'Flower', b'Chair', b'Tree', b'Table',\n",
      "       b'Tree', b'Tree', b'Tree', b'Tree', b'Tree', b'Tree', b'Chair',\n",
      "       b'Flower', b'Chair', b'Table', b'Flower', b'Flower', b'Table',\n",
      "       b'Tree', b'Table', b'Tree', b'Chair', b'Tree', b'Flower', b'Tree',\n",
      "       b'Chair', b'Tree', b'Table', b'Window', b'Tree', b'Tree', b'Tree',\n",
      "       b'Person', b'Window', b'Tree', b'Kitchen & dining room table',\n",
      "       b'Table', b'Umbrella', b'Flower', b'Flower'], dtype=object), 'detection_scores': array([0.3765772 , 0.3473224 , 0.32187063, 0.2844692 , 0.252298  ,\n",
      "       0.21863902, 0.21550015, 0.21180788, 0.20861351, 0.20820129,\n",
      "       0.20579556, 0.1970036 , 0.16537362, 0.16522202, 0.16399896,\n",
      "       0.16175792, 0.15904829, 0.15305698, 0.15085104, 0.14960766,\n",
      "       0.14908716, 0.14816138, 0.14713651, 0.14691901, 0.14652473,\n",
      "       0.14401034, 0.14371088, 0.14278436, 0.14215821, 0.14187151,\n",
      "       0.14135218, 0.14126116, 0.1401403 , 0.14006689, 0.13956839,\n",
      "       0.1385769 , 0.13807973, 0.1365954 , 0.13603148, 0.13237697,\n",
      "       0.13161516, 0.13148761, 0.13111785, 0.13078484, 0.13029683,\n",
      "       0.13016969, 0.12834069, 0.12724724, 0.12670505, 0.12630624,\n",
      "       0.12574825, 0.12539646, 0.12488246, 0.12438697, 0.12377411,\n",
      "       0.12259111, 0.12231299, 0.1210233 , 0.11768624, 0.1176098 ,\n",
      "       0.11675525, 0.11671489, 0.11646685, 0.11625904, 0.11608419,\n",
      "       0.11562768, 0.11539444, 0.11485761, 0.11403474, 0.11400717,\n",
      "       0.11392587, 0.11355361, 0.11322773, 0.11233023, 0.11186761,\n",
      "       0.11146423, 0.11138517, 0.11125621, 0.11125278, 0.11104095,\n",
      "       0.11051321, 0.10970974, 0.10951686, 0.10945681, 0.10942262,\n",
      "       0.10937944, 0.10925493, 0.1088095 , 0.10818398, 0.10761443,\n",
      "       0.107577  , 0.10750577, 0.10749477, 0.10738507, 0.10615295,\n",
      "       0.10562444, 0.10539064, 0.10508284, 0.10499167, 0.10454145],\n",
      "      dtype=float32), 'detection_class_names': array([b'/m/01mzpv', b'/m/0hnnb', b'/m/0h8n5zk', b'/m/04bcr3',\n",
      "       b'/m/01mzpv', b'/m/01mzpv', b'/m/01mzpv', b'/m/01mzpv',\n",
      "       b'/m/01mzpv', b'/m/04bcr3', b'/m/01mzpv', b'/m/07j7r', b'/m/07j7r',\n",
      "       b'/m/01mzpv', b'/m/07j7r', b'/m/01mzpv', b'/m/07j7r', b'/m/07j7r',\n",
      "       b'/m/07j7r', b'/m/07j7r', b'/m/07j7r', b'/m/07j7r', b'/m/01mzpv',\n",
      "       b'/m/01mzpv', b'/m/0c9ph5', b'/m/07j7r', b'/m/07j7r', b'/m/0c9ph5',\n",
      "       b'/m/0hnnb', b'/m/07j7r', b'/m/07j7r', b'/m/07j7r', b'/m/07j7r',\n",
      "       b'/m/04m6gz', b'/m/04bcr3', b'/m/07j7r', b'/m/07j7r', b'/m/07j7r',\n",
      "       b'/m/04bcr3', b'/m/07j7r', b'/m/07j7r', b'/m/0c9ph5', b'/m/04bcr3',\n",
      "       b'/m/07j7r', b'/m/07j7r', b'/m/07j7r', b'/m/07j7r', b'/m/07j7r',\n",
      "       b'/m/07j7r', b'/m/01mzpv', b'/m/07j7r', b'/m/0c9ph5', b'/m/04bcr3',\n",
      "       b'/m/07j7r', b'/m/07j7r', b'/m/01mzpv', b'/m/07j7r', b'/m/01mzpv',\n",
      "       b'/m/07j7r', b'/m/07j7r', b'/m/07j7r', b'/m/0c9ph5', b'/m/01mzpv',\n",
      "       b'/m/07j7r', b'/m/04bcr3', b'/m/07j7r', b'/m/07j7r', b'/m/07j7r',\n",
      "       b'/m/07j7r', b'/m/07j7r', b'/m/07j7r', b'/m/01mzpv', b'/m/0c9ph5',\n",
      "       b'/m/01mzpv', b'/m/04bcr3', b'/m/0c9ph5', b'/m/0c9ph5',\n",
      "       b'/m/04bcr3', b'/m/07j7r', b'/m/04bcr3', b'/m/07j7r', b'/m/01mzpv',\n",
      "       b'/m/07j7r', b'/m/0c9ph5', b'/m/07j7r', b'/m/01mzpv', b'/m/07j7r',\n",
      "       b'/m/04bcr3', b'/m/0d4v4', b'/m/07j7r', b'/m/07j7r', b'/m/07j7r',\n",
      "       b'/m/01g317', b'/m/0d4v4', b'/m/07j7r', b'/m/0h8n5zk',\n",
      "       b'/m/04bcr3', b'/m/0hnnb', b'/m/0c9ph5', b'/m/0c9ph5'],\n",
      "      dtype=object), 'detection_class_labels': array([ 97, 557, 544, 281,  97,  97,  97,  97,  97, 281,  97, 391, 391,\n",
      "        97, 391,  97, 391, 391, 391, 391, 391, 391,  97,  97, 456, 391,\n",
      "       391, 456, 557, 391, 391, 391, 391, 295, 281, 391, 391, 391, 281,\n",
      "       391, 391, 456, 281, 391, 391, 391, 391, 391, 391,  97, 391, 456,\n",
      "       281, 391, 391,  97, 391,  97, 391, 391, 391, 456,  97, 391, 281,\n",
      "       391, 391, 391, 391, 391, 391,  97, 456,  97, 281, 456, 456, 281,\n",
      "       391, 281, 391,  97, 391, 456, 391,  97, 391, 281, 485, 391, 391,\n",
      "       391,  69, 485, 391, 544, 281, 557, 456, 456]), 'detection_boxes': array([[6.35426402e-01, 3.93931627e-01, 9.05239463e-01, 5.10560572e-01],\n",
      "       [2.02848613e-01, 0.00000000e+00, 7.84581840e-01, 5.71182132e-01],\n",
      "       [6.52016938e-01, 6.63962960e-01, 9.85513628e-01, 9.97349620e-01],\n",
      "       [6.70319259e-01, 6.82858884e-01, 9.99053299e-01, 9.91601765e-01],\n",
      "       [6.23315930e-01, 2.86662996e-01, 9.00639892e-01, 3.88174117e-01],\n",
      "       [7.04092562e-01, 6.47114158e-01, 1.00000000e+00, 7.82915235e-01],\n",
      "       [6.36693716e-01, 3.51130724e-01, 9.06901479e-01, 4.74104106e-01],\n",
      "       [7.12758303e-01, 8.50519359e-01, 1.00000000e+00, 9.99862015e-01],\n",
      "       [6.10554278e-01, 4.82094735e-01, 8.72938693e-01, 5.97810745e-01],\n",
      "       [7.48815596e-01, 9.07558203e-03, 1.00000000e+00, 2.92587310e-01],\n",
      "       [6.24981046e-01, 4.28928673e-01, 9.01050568e-01, 5.36379695e-01],\n",
      "       [0.00000000e+00, 6.53666258e-03, 5.16124904e-01, 1.00000000e+00],\n",
      "       [2.83331871e-02, 2.10696459e-03, 5.20840585e-01, 4.68235344e-01],\n",
      "       [7.01059282e-01, 7.34821796e-01, 9.99436915e-01, 9.14844632e-01],\n",
      "       [4.85584140e-03, 1.34183466e-02, 2.78224975e-01, 4.96311098e-01],\n",
      "       [6.45932436e-01, 6.52044535e-01, 1.00000000e+00, 8.51055980e-01],\n",
      "       [3.47897410e-03, 3.13948095e-03, 3.85179937e-01, 3.78812551e-01],\n",
      "       [3.37114036e-02, 2.79249728e-01, 6.23699307e-01, 7.08310366e-01],\n",
      "       [0.00000000e+00, 6.06144071e-01, 7.35832334e-01, 9.88100767e-01],\n",
      "       [6.08482957e-03, 4.84265745e-01, 2.86744595e-01, 9.79331911e-01],\n",
      "       [1.02346241e-02, 4.41139668e-01, 5.93775511e-01, 9.55572009e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 7.25835681e-01, 3.75789762e-01],\n",
      "       [6.71411693e-01, 7.74204612e-01, 9.81708705e-01, 9.76293087e-01],\n",
      "       [6.16125703e-01, 5.54965615e-01, 8.79071236e-01, 6.71069980e-01],\n",
      "       [5.64150751e-01, 7.03852475e-01, 5.96453369e-01, 7.25156963e-01],\n",
      "       [5.80859184e-03, 1.09426975e-02, 5.61506271e-01, 2.50496864e-01],\n",
      "       [5.06569505e-01, 2.01909631e-01, 6.12220049e-01, 2.56536484e-01],\n",
      "       [1.92620605e-01, 6.68122053e-01, 2.19128221e-01, 6.85550213e-01],\n",
      "       [1.13648236e-01, 1.08173341e-02, 9.08728778e-01, 4.28270936e-01],\n",
      "       [2.38536298e-02, 1.55517757e-01, 5.65589666e-01, 8.30414236e-01],\n",
      "       [4.98818606e-03, 8.42435181e-01, 2.15574563e-01, 1.00000000e+00],\n",
      "       [2.46904790e-03, 3.11648577e-01, 3.59815657e-01, 8.55700731e-01],\n",
      "       [0.00000000e+00, 5.34510553e-01, 4.54065949e-01, 9.16436017e-01],\n",
      "       [4.54803705e-01, 8.87513161e-02, 9.68449950e-01, 9.78595018e-01],\n",
      "       [6.14182830e-01, 3.24572086e-01, 7.93885112e-01, 5.42999089e-01],\n",
      "       [2.31199279e-01, 7.66951144e-01, 6.13027215e-01, 8.85276377e-01],\n",
      "       [4.84177470e-03, 6.46952987e-02, 2.70436108e-01, 9.92977560e-01],\n",
      "       [2.85875797e-03, 1.66908681e-01, 3.60586286e-01, 6.99280441e-01],\n",
      "       [7.80944288e-01, 7.84322619e-04, 9.77019846e-01, 2.23038718e-01],\n",
      "       [5.22952139e-01, 1.73676223e-01, 5.99078238e-01, 2.10724145e-01],\n",
      "       [5.76883554e-04, 0.00000000e+00, 4.05517906e-01, 6.17605209e-01],\n",
      "       [1.23321369e-01, 5.98604441e-01, 1.52483508e-01, 6.21813059e-01],\n",
      "       [6.67396784e-01, 3.30906928e-01, 8.59207988e-01, 5.40066719e-01],\n",
      "       [4.00891900e-03, 1.15416467e-01, 6.17565155e-01, 3.46126914e-01],\n",
      "       [3.33461165e-03, 4.44510579e-03, 4.64462608e-01, 1.59798428e-01],\n",
      "       [5.38238883e-03, 6.04620039e-01, 3.62801582e-01, 1.00000000e+00],\n",
      "       [0.00000000e+00, 5.40301949e-03, 2.39316732e-01, 2.11593837e-01],\n",
      "       [0.00000000e+00, 3.25028598e-01, 4.60610986e-01, 6.98717415e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.73077703e-01, 6.02468491e-01],\n",
      "       [6.61296844e-01, 5.62951207e-01, 9.89043117e-01, 7.77542353e-01],\n",
      "       [0.00000000e+00, 3.70323658e-04, 1.94352433e-01, 4.02144134e-01],\n",
      "       [1.12635687e-01, 6.57533586e-01, 1.52701899e-01, 6.84616864e-01],\n",
      "       [6.13733888e-01, 3.94377589e-01, 7.90984631e-01, 5.91223955e-01],\n",
      "       [0.00000000e+00, 1.34713978e-01, 5.78923225e-01, 4.50424284e-01],\n",
      "       [1.71484798e-03, 7.38491178e-01, 2.29954600e-01, 8.96358609e-01],\n",
      "       [5.21553755e-01, 2.52208889e-01, 9.46196198e-01, 4.50659871e-01],\n",
      "       [1.20343298e-01, 3.15780193e-02, 6.42005801e-01, 5.26550710e-01],\n",
      "       [6.00488484e-01, 3.49315405e-01, 9.44818318e-01, 5.38550854e-01],\n",
      "       [5.27917743e-01, 1.04587466e-01, 6.02359653e-01, 1.53549224e-01],\n",
      "       [1.46335363e-03, 1.01016611e-02, 2.98864961e-01, 2.82098889e-01],\n",
      "       [0.00000000e+00, 6.04426026e-01, 1.88384891e-01, 9.91740346e-01],\n",
      "       [6.73610270e-02, 6.65891886e-01, 1.13406822e-01, 6.87337756e-01],\n",
      "       [6.30621076e-01, 6.01179302e-01, 9.11242604e-01, 7.23160565e-01],\n",
      "       [0.00000000e+00, 9.10808563e-01, 2.08506972e-01, 1.00000000e+00],\n",
      "       [6.20523393e-01, 7.80464411e-01, 7.20977366e-01, 9.86588478e-01],\n",
      "       [1.75546855e-03, 6.70813382e-01, 2.24374682e-01, 8.52373779e-01],\n",
      "       [4.76159155e-03, 5.25352478e-01, 2.26250365e-01, 6.85250998e-01],\n",
      "       [1.76056132e-01, 8.07331562e-01, 6.11376941e-01, 9.32890654e-01],\n",
      "       [5.31882167e-01, 4.29350324e-03, 6.78875327e-01, 6.17673844e-02],\n",
      "       [0.00000000e+00, 7.68228233e-01, 3.26580405e-01, 1.00000000e+00],\n",
      "       [3.47515523e-01, 1.44343078e-03, 6.89813673e-01, 1.51051030e-01],\n",
      "       [6.82877123e-01, 6.22381449e-01, 9.83839571e-01, 7.43364930e-01],\n",
      "       [5.67573547e-01, 8.71862590e-01, 5.95564961e-01, 8.94039094e-01],\n",
      "       [6.61492586e-01, 7.51646876e-01, 9.24531579e-01, 8.91877890e-01],\n",
      "       [7.40454078e-01, 0.00000000e+00, 9.28229451e-01, 2.17928350e-01],\n",
      "       [1.39279038e-01, 6.81473911e-02, 1.58344597e-01, 8.30761939e-02],\n",
      "       [7.05397651e-02, 6.11498237e-01, 1.04435824e-01, 6.31122112e-01],\n",
      "       [6.40226424e-01, 7.69749761e-01, 7.80349433e-01, 9.91416693e-01],\n",
      "       [0.00000000e+00, 2.47700989e-01, 5.02293348e-01, 4.58387434e-01],\n",
      "       [6.68896139e-01, 3.87404561e-01, 8.48312557e-01, 5.86494446e-01],\n",
      "       [0.00000000e+00, 4.76855993e-01, 2.17994049e-01, 6.39459968e-01],\n",
      "       [5.85142732e-01, 1.40876949e-01, 9.76275325e-01, 3.43534440e-01],\n",
      "       [0.00000000e+00, 5.45303822e-01, 4.54008967e-01, 7.64407158e-01],\n",
      "       [5.66803813e-01, 7.57161677e-01, 5.98336339e-01, 7.78935730e-01],\n",
      "       [0.00000000e+00, 4.34398532e-01, 1.70715183e-01, 1.00000000e+00],\n",
      "       [6.18483067e-01, 4.24580544e-01, 9.87159967e-01, 6.53812528e-01],\n",
      "       [0.00000000e+00, 9.39876065e-02, 2.27986187e-01, 2.67414480e-01],\n",
      "       [6.43509805e-01, 6.14276052e-01, 9.12907422e-01, 1.00000000e+00],\n",
      "       [3.28407437e-01, 4.85126555e-01, 3.70120972e-01, 5.09349644e-01],\n",
      "       [3.23125720e-03, 7.68917680e-01, 1.74934074e-01, 1.00000000e+00],\n",
      "       [0.00000000e+00, 6.31787896e-01, 4.44661081e-01, 8.60841155e-01],\n",
      "       [3.32688868e-01, 4.24011946e-01, 4.48863983e-01, 4.86508191e-01],\n",
      "       [6.40303016e-01, 4.74422984e-02, 7.92013168e-01, 1.17050618e-01],\n",
      "       [3.80032212e-01, 4.89378124e-01, 4.75672215e-01, 5.19140303e-01],\n",
      "       [6.05315268e-02, 7.49556184e-01, 3.50223929e-01, 8.97660851e-01],\n",
      "       [5.68807602e-01, 2.69505531e-01, 9.23009396e-01, 6.04510427e-01],\n",
      "       [6.43533707e-01, 6.96792483e-01, 7.90784836e-01, 9.57338929e-01],\n",
      "       [1.35762364e-01, 0.00000000e+00, 8.30077648e-01, 2.91149855e-01],\n",
      "       [1.76811442e-01, 5.56959629e-01, 2.03859612e-01, 5.74594975e-01],\n",
      "       [2.85183758e-01, 7.62915730e-01, 3.24228734e-01, 7.83919930e-01]],\n",
      "      dtype=float32)}\n",
      "Inference time:  0.05077505111694336\n"
     ]
    }
   ],
   "source": [
    "# Loads the image for the network to use\n",
    "def load_img(path):\n",
    "  img = tf.io.read_file(path)\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  return img\n",
    "\n",
    "# Running the detector\n",
    "def run_detector(detector, path):\n",
    "  img = load_img(path)\n",
    "\n",
    "  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "  start_time = time.time()\n",
    "  result = detector(converted_img)\n",
    "  end_time = time.time()\n",
    "\n",
    "  result = {key:value.numpy() for key,value in result.items()}\n",
    "\n",
    "  print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
    "  print(result)\n",
    "  print(\"Inference time: \", end_time-start_time)\n",
    "\n",
    "  image_with_boxes = draw_boxes(\n",
    "      img.numpy(), result[\"detection_boxes\"],\n",
    "      result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
    "\n",
    "  #display_image(image_with_boxes)\n",
    "\n",
    "run_detector(detector, downloaded_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1M_sVGzwVlrT"
   },
   "source": [
    "Let's now use the pretrained model to make an inference on other 3 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RFG2VFJxWPUg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coleoptera\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 objects.\n",
      "[0.9778602  0.9626732  0.94962853 0.94943225 0.94020146 0.8503012\n",
      " 0.8173051  0.57327724 0.45883006 0.350584   0.17450964 0.09852738\n",
      " 0.09182353 0.07497085 0.04629605 0.04598429 0.04143474 0.03997439\n",
      " 0.03943128 0.03942169 0.03021665 0.02932613 0.02918878 0.02790124\n",
      " 0.02694958 0.02456733 0.02300434 0.02189109 0.01929941 0.01920215\n",
      " 0.01838593 0.0180631  0.01669725 0.01660074 0.0164266  0.01589503\n",
      " 0.0150904  0.01479315 0.01426297 0.01311702 0.01241734 0.01211264\n",
      " 0.01042742 0.01031207 0.01011779 0.00950792 0.00940581 0.00924837\n",
      " 0.00874841 0.00818658 0.00766253 0.00733435 0.0073221  0.00723879\n",
      " 0.00710741 0.00708327 0.00654369 0.00645531 0.00606113 0.00528344\n",
      " 0.00512487 0.00502358 0.00472783 0.00472186 0.00454735 0.00447636\n",
      " 0.00402213 0.00397097 0.00393712 0.00356663 0.00334545 0.00329525\n",
      " 0.00312949 0.00292099 0.00276557 0.00274509 0.00271724 0.00264512\n",
      " 0.0024809  0.0024756  0.00241141 0.00237939 0.00232675 0.00225014\n",
      " 0.0022367  0.00214546 0.00213519 0.00213335 0.00208059 0.00204773\n",
      " 0.00200016 0.00198733 0.00196546 0.00194581 0.00185387 0.00182806\n",
      " 0.00182674 0.00173877 0.00172374 0.00168536]\n",
      "Inference time:  26.9812068939209\n",
      "detect_img total time: 78.17420315742493\n",
      "\n",
      "Campus\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 objects.\n",
      "[0.9438628  0.8966501  0.81166774 0.774244   0.73853165 0.27011248\n",
      " 0.24054703 0.17063358 0.17014578 0.12994286 0.07622842 0.07121973\n",
      " 0.07017564 0.06897268 0.05690185 0.04029793 0.04001265 0.03844966\n",
      " 0.03647082 0.03269174 0.02800994 0.02719952 0.02541589 0.02319722\n",
      " 0.02232638 0.02206668 0.02131863 0.02130859 0.02122093 0.02108924\n",
      " 0.01785898 0.01752537 0.01751808 0.01701841 0.01380865 0.01368599\n",
      " 0.01203154 0.01146142 0.01145623 0.01117016 0.01079447 0.01072222\n",
      " 0.01045169 0.01023653 0.00959844 0.00958574 0.0095366  0.00917782\n",
      " 0.0091518  0.00913873 0.00879276 0.00869646 0.00863881 0.00855919\n",
      " 0.00845344 0.00845183 0.00820703 0.00805747 0.00768932 0.00747154\n",
      " 0.0074619  0.00728051 0.00680106 0.00674349 0.00673483 0.00657167\n",
      " 0.00645279 0.00641499 0.00632667 0.00628989 0.00610058 0.00607276\n",
      " 0.00590488 0.00535663 0.00524032 0.004859   0.00481867 0.004723\n",
      " 0.00470682 0.00459157 0.00452992 0.00452304 0.00449044 0.00437413\n",
      " 0.00418169 0.00417229 0.0040741  0.00391664 0.00385554 0.00385135\n",
      " 0.00375016 0.00374697 0.00374623 0.0037082  0.00348372 0.0034227\n",
      " 0.00341627 0.00331985 0.0032947  0.00312095]\n",
      "Inference time:  26.992531061172485\n",
      "detect_img total time: 80.381019115448\n",
      "\n",
      "Birds\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 objects.\n",
      "[0.9785452  0.8780808  0.8361889  0.7508799  0.57874113 0.4969744\n",
      " 0.16719551 0.16628632 0.1475123  0.13507499 0.13296469 0.11149114\n",
      " 0.09334902 0.08116634 0.07981076 0.0734387  0.0727512  0.06550292\n",
      " 0.06246734 0.04950894 0.04537462 0.03836504 0.0358756  0.03349325\n",
      " 0.03225903 0.02772932 0.02564834 0.02446795 0.02171508 0.02169244\n",
      " 0.02025024 0.01972702 0.01649113 0.01350184 0.01324136 0.01307821\n",
      " 0.01302984 0.01294602 0.01261301 0.01256995 0.01206391 0.01167373\n",
      " 0.01106824 0.00954537 0.00919462 0.00900873 0.00886381 0.00884432\n",
      " 0.00842483 0.00752402 0.00719706 0.00671171 0.00624359 0.0061905\n",
      " 0.00613227 0.00604937 0.00604339 0.005962   0.00570473 0.00567942\n",
      " 0.00565076 0.00544587 0.0054434  0.00530543 0.00529949 0.0048144\n",
      " 0.00464277 0.00438933 0.00436841 0.00426381 0.00415862 0.00410738\n",
      " 0.003955   0.00394875 0.00390861 0.00357755 0.00356154 0.00340583\n",
      " 0.00337822 0.00323494 0.00318031 0.00313879 0.00294527 0.00289319\n",
      " 0.00285873 0.00285349 0.00277905 0.00277189 0.00268283 0.00265784\n",
      " 0.00263416 0.00260221 0.00254686 0.00250658 0.00246004 0.00243876\n",
      " 0.0023974  0.0023389  0.00233793 0.00233254]\n",
      "Inference time:  27.012528896331787\n",
      "detect_img total time: 77.47398781776428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_urls = {\"Coleoptera\": \"https://upload.wikimedia.org/wikipedia/commons/1/1b/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg\",\n",
    "              \"Campus\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg\",\n",
    "              \"Birds\": \"https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg\"}\n",
    "\n",
    "\n",
    "def detect_img(image_url):\n",
    "  start_time = time.time()\n",
    "  image_path = download_and_resize_image(image_url, 640, 480, display=False)  # downloaded image (at a 640x480 resolution) to be fed to the pretrained\n",
    "  detector = hub.load(module_handle).signatures['default']    \n",
    "  run_detector(detector, image_path) # make the pretrained run\n",
    "  end_time = time.time()\n",
    "  print(\"detect_img total time:\", end_time-start_time)  # printing the elapsed time for the inference\n",
    "\n",
    "# Applying detect_img on the 3 new images\n",
    "for image in image_urls:\n",
    "    print(image)\n",
    "    detect_img(image_urls[image])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnX4ZVAHqfaG"
   },
   "source": [
    "Let's now try running these experiments on *MobileNet V2*, another a convolutional neural network-based architecture for object detection. You can find an in-depth description of MobileNet V2 [here](https://machinethink.net/blog/mobilenet-v2/); the pretrained model can be downloaded [from this link](https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IgOKj0GyqflZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 objects.\n",
      "[0.3765772  0.3473224  0.32187063 0.2844692  0.252298   0.21863902\n",
      " 0.21550015 0.21180788 0.20861351 0.20820129 0.20579556 0.1970036\n",
      " 0.16537362 0.16522202 0.16399896 0.16175792 0.15904829 0.15305698\n",
      " 0.15085104 0.14960766 0.14908716 0.14816138 0.14713651 0.14691901\n",
      " 0.14652473 0.14401034 0.14371088 0.14278436 0.14215821 0.14187151\n",
      " 0.14135218 0.14126116 0.1401403  0.14006689 0.13956839 0.1385769\n",
      " 0.13807973 0.1365954  0.13603148 0.13237697 0.13161516 0.13148761\n",
      " 0.13111785 0.13078484 0.13029683 0.13016969 0.12834069 0.12724724\n",
      " 0.12670505 0.12630624 0.12574825 0.12539646 0.12488246 0.12438697\n",
      " 0.12377411 0.12259111 0.12231299 0.1210233  0.11768624 0.1176098\n",
      " 0.11675525 0.11671489 0.11646685 0.11625904 0.11608419 0.11562768\n",
      " 0.11539444 0.11485761 0.11403474 0.11400717 0.11392587 0.11355361\n",
      " 0.11322773 0.11233023 0.11186761 0.11146423 0.11138517 0.11125621\n",
      " 0.11125278 0.11104095 0.11051321 0.10970974 0.10951686 0.10945681\n",
      " 0.10942262 0.10937944 0.10925493 0.1088095  0.10818398 0.10761443\n",
      " 0.107577   0.10750577 0.10749477 0.10738507 0.10615295 0.10562444\n",
      " 0.10539064 0.10508284 0.10499167 0.10454145]\n",
      "Inference time:  4.582036018371582\n",
      "Coleoptera\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 objects.\n",
      "[0.903319   0.81101316 0.8081393  0.72810626 0.7162817  0.6965114\n",
      " 0.6740742  0.39919484 0.3959492  0.3457873  0.3313371  0.29408523\n",
      " 0.25905573 0.25874218 0.24704593 0.24266851 0.16455656 0.14731571\n",
      " 0.13561413 0.12256306 0.1073859  0.10717526 0.10425571 0.10405046\n",
      " 0.10098594 0.10031408 0.09838665 0.09403858 0.09398621 0.08897996\n",
      " 0.08896789 0.08833358 0.08786052 0.08754873 0.08682534 0.08631313\n",
      " 0.08615479 0.08604211 0.08387071 0.08344099 0.08254766 0.08232611\n",
      " 0.08231997 0.08112463 0.08071682 0.08002344 0.07910737 0.07738921\n",
      " 0.07716912 0.07709894 0.07690558 0.07685614 0.07680035 0.0756444\n",
      " 0.07527956 0.07525915 0.07510081 0.07503638 0.07426032 0.07382214\n",
      " 0.07351065 0.07335415 0.07315612 0.07276997 0.07173935 0.07164529\n",
      " 0.07137984 0.07118767 0.07067242 0.07062802 0.07026353 0.06986114\n",
      " 0.06972089 0.0689595  0.06884432 0.0685418  0.06838804 0.06828025\n",
      " 0.06782037 0.06771821 0.06762806 0.06746873 0.06712642 0.06673852\n",
      " 0.06658757 0.06640419 0.06593388 0.06573033 0.06548932 0.06503245\n",
      " 0.06492704 0.06492075 0.06482548 0.06480527 0.06461817 0.06458569\n",
      " 0.06451064 0.06432778 0.06303841 0.06291324]\n",
      "Inference time:  4.36513090133667\n",
      "detect_img total time: 19.056154012680054\n",
      "Campus\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 objects.\n",
      "[0.3088279  0.20544696 0.19057247 0.13318908 0.13017592 0.11788777\n",
      " 0.1114637  0.09950134 0.09708747 0.08934605 0.08581877 0.08409065\n",
      " 0.0837476  0.08128947 0.08090448 0.0796771  0.07665145 0.07351854\n",
      " 0.06787941 0.06763098 0.06711239 0.06648007 0.06524613 0.06407431\n",
      " 0.06344062 0.06337002 0.06195149 0.06105059 0.0608533  0.06070372\n",
      " 0.0601666  0.05848241 0.05768564 0.05741993 0.0573009  0.05684248\n",
      " 0.05608249 0.05582294 0.05571845 0.05448851 0.05446702 0.05443513\n",
      " 0.05435085 0.05417299 0.05415317 0.05264318 0.05168974 0.05060163\n",
      " 0.05004039 0.04965428 0.04951808 0.04944339 0.04944021 0.04930982\n",
      " 0.04898804 0.0489732  0.04827729 0.0479933  0.04759657 0.04752758\n",
      " 0.04606029 0.04595795 0.04588827 0.04564151 0.04560599 0.04542089\n",
      " 0.04541913 0.04503351 0.04479921 0.04464462 0.04455972 0.04444045\n",
      " 0.04443133 0.04429397 0.04353622 0.04304466 0.04298383 0.04291523\n",
      " 0.0416919  0.0416204  0.04161537 0.04138911 0.04138735 0.04138336\n",
      " 0.04104346 0.04101482 0.04093653 0.04088524 0.04069898 0.04067159\n",
      " 0.04045349 0.04009029 0.03958002 0.03935274 0.03915095 0.03914359\n",
      " 0.03908297 0.03900453 0.03881696 0.03871056]\n",
      "Inference time:  4.478224039077759\n",
      "detect_img total time: 15.173020839691162\n",
      "Birds\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 objects.\n",
      "[0.38031673 0.23105821 0.22166541 0.20905161 0.1764996  0.17124161\n",
      " 0.14889076 0.14184913 0.1369287  0.1288428  0.12685049 0.1250625\n",
      " 0.11813104 0.11217046 0.10798398 0.10727975 0.10532096 0.10321879\n",
      " 0.10308805 0.10076255 0.09951413 0.09887889 0.09655422 0.09627086\n",
      " 0.0962474  0.0959844  0.09588021 0.09553578 0.09172225 0.09142306\n",
      " 0.0907211  0.09047785 0.08967301 0.0894784  0.08920169 0.08914313\n",
      " 0.08908731 0.08624831 0.08569485 0.08528277 0.08520728 0.085105\n",
      " 0.08295664 0.08096156 0.08068433 0.08062741 0.08033827 0.08031407\n",
      " 0.07976875 0.07971889 0.07947978 0.07942268 0.07891569 0.07854143\n",
      " 0.0781672  0.07811797 0.07781231 0.07778296 0.07778034 0.07765561\n",
      " 0.07704484 0.07676065 0.07637134 0.07579958 0.07535803 0.07531258\n",
      " 0.075234   0.07503754 0.07499233 0.07496595 0.07457471 0.07425612\n",
      " 0.07412714 0.07387203 0.07381183 0.07378682 0.07369411 0.07359469\n",
      " 0.07347983 0.0734565  0.07316697 0.07313499 0.07303286 0.07301268\n",
      " 0.07283393 0.07281467 0.07226551 0.07199922 0.07144439 0.07114467\n",
      " 0.07110715 0.07000425 0.06981525 0.06980383 0.06943142 0.06934369\n",
      " 0.0693059  0.06925941 0.06908518 0.06907412]\n",
      "Inference time:  4.330379009246826\n",
      "detect_img total time: 14.671875\n"
     ]
    }
   ],
   "source": [
    "# Loading the pretrained of MobileNet V2 and making it run on the \"Naxos Taverna\" image\n",
    "module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\n",
    "detector = hub.load(module_handle).signatures['default'] \n",
    "\n",
    "run_detector(detector, downloaded_image_path)\n",
    "\n",
    "def detect_img(image_url):\n",
    "  start_time = time.time()\n",
    "  image_path = download_and_resize_image(image_url, 640, 480, display=False)  # downloaded image (at a 640x480 resolution) to be fed to the pretrained\n",
    "  detector = hub.load(module_handle).signatures['default']    \n",
    "  run_detector(detector, image_path) # make the pretrained run\n",
    "  end_time = time.time()\n",
    "  print(\"detect_img total time:\", end_time-start_time)  # printing the elapsed time for the inference\n",
    "\n",
    "\n",
    "# Applying detect_img on the 3 new images\n",
    "for image in image_urls:\n",
    "    print(image)\n",
    "    detect_img(image_urls[image]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKtV18HT9MIlKl/J3AJ4+G",
   "collapsed_sections": [],
   "name": "07_object_detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
